{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK4SSIkcMnDG"
   },
   "source": [
    "1. Из ноутбуков по практике \"Рекуррентные и одномерные сверточные нейронные сети\" выберите лучшую сеть, либо создайте свою. \n",
    "2. Запустите раздел \"Подготовка\"\n",
    "3. Подготовьте датасет с параметрами `VOCAB_SIZE=20'000`, `WIN_SIZE=1000`, `WIN_HOP=100`, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для  всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
    "4. Поменяйте размер словаря tokenaizera (`VOCAB_SIZE`) на `5000`, `10000`, `40000`.  Пересоздайте датасеты, при этом оставьте `WIN_SIZE=1000`, `WIN_HOP=100`.\n",
    "Обучите выбранную нейронку на этих датасетах.  Сделайте выводы об  изменении  точности распознавания авторов текстов. Результаты сведите в таблицу\n",
    "5. Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы  (`WIN_SIZE`, `WIN_HOP`) используя значения (`500`,`50`) и (`2000`,`200`). Пересоздайте датасеты, при этом оставьте `VOCAB_SIZE=20000`. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об  изменении точности распознавания авторов текстов. \n",
    "\n",
    "Результаты всей работы сведите в таблицу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lszru6V_3g3"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O4rebeM0PyTH",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Работа с массивами данных\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Функции-утилиты для работы с категориальными данными\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Работа с массивами данных\n",
    "import numpy as np \n",
    "\n",
    "# Функции-утилиты для работы с категориальными данными\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# Класс для конструирования последовательной модели нейронной сети\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Основные слои\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "# Токенизатор для преобразование текстов в последовательности\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Рисование схемы модели\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Матрица ошибок классификатора\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Загрузка датасетов из облака google\n",
    "import gdown\n",
    "\n",
    "# Функции операционной системы\n",
    "import os\n",
    "\n",
    "# Работа со временем\n",
    "import time\n",
    "\n",
    "# Регулярные выражения\n",
    "import re\n",
    "\n",
    "# Отрисовка графиков\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Вывод объектов в ячейке colab\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "f-7of32uP4S-",
    "outputId": "36549b2b-2269-436e-b6e8-6b13888458cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'writers.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим датасет из облака\n",
    "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', None, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsxkrH9rP7MS",
    "outputId": "e1444839-e844-4cae-93d9-f4df8468e8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  writers.zip\n",
      "  inflating: writers/(Клиффорд_Саймак) Обучающая_5 вместе.txt  \n",
      "  inflating: writers/(Клиффорд_Саймак) Тестовая_2 вместе.txt  \n",
      "  inflating: writers/(Макс Фрай) Обучающая_5 вместе.txt  \n",
      "  inflating: writers/(Макс Фрай) Тестовая_2 вместе.txt  \n",
      "  inflating: writers/(О. Генри) Обучающая_50 вместе.txt  \n",
      "  inflating: writers/(О. Генри) Тестовая_20 вместе.txt  \n",
      "  inflating: writers/(Рэй Брэдберри) Обучающая_22 вместе.txt  \n",
      "  inflating: writers/(Рэй Брэдберри) Тестовая_8 вместе.txt  \n",
      "  inflating: writers/(Стругацкие) Обучающая_5 вместе.txt  \n",
      "  inflating: writers/(Стругацкие) Тестовая_2 вместе.txt  \n",
      "  inflating: writers/(Булгаков) Обучающая_5 вместе.txt  \n",
      "  inflating: writers/(Булгаков) Тестовая_2 вместе.txt  \n"
     ]
    }
   ],
   "source": [
    "# Распакуем архив в папку writers\n",
    "!unzip -o writers.zip -d writers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y3fICNeqP9li"
   },
   "outputs": [],
   "source": [
    "# Настройка констант для загрузки данных\n",
    "FILE_DIR  = 'writers'                     # Папка с текстовыми файлами\n",
    "SIG_TRAIN = 'обучающая'                   # Признак обучающей выборки в имени файла\n",
    "SIG_TEST  = 'тестовая'                    # Признак тестовой выборки в имени файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulfk9v7TQBjp",
    "outputId": "e561515b-543f-426b-a004-5196a6fb49b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавление класса \"Клиффорд_Саймак\"\n",
      "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n",
      "Добавление класса \"Макс Фрай\"\n",
      "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
      "Добавление класса \"Стругацкие\"\n",
      "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n",
      "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
      "Добавление класса \"О. Генри\"\n",
      "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
      "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
      "Добавление класса \"Рэй Брэдберри\"\n",
      "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
      "Добавление класса \"Булгаков\"\n",
      "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
      "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
      "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
      "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n",
      "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n"
     ]
    }
   ],
   "source": [
    "# Подготовим пустые списки\n",
    "\n",
    "CLASS_LIST = []  # Список классов \n",
    "text_train = []  # Список для обучающей выборки\n",
    "text_test = []   # Список для тестовой выборки\n",
    "\n",
    "# Получим списка файлов в папке\n",
    "file_list = os.listdir(FILE_DIR)\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Выделяем имя класса и типа выборки из имени файла\n",
    "    m = re.match('\\((.+)\\) (\\S+)_', file_name)\n",
    "    # Если выделение получилось, то файл обрабатываем\n",
    "    if m:\n",
    "\n",
    "        # Получим имя класса\n",
    "        class_name = m[1]\n",
    "\n",
    "        # Получим имя выборки\n",
    "        subset_name = m[2].lower()\n",
    "\n",
    "        # Проверим тип выборки \n",
    "        is_train = SIG_TRAIN in subset_name\n",
    "        is_test = SIG_TEST in subset_name\n",
    "\n",
    "        # Если тип выборки обучающая либо тестовая - файл обрабатываем\n",
    "        if is_train or is_test:\n",
    "\n",
    "            # Добавляем новый класс, если его еще нет в списке\n",
    "            if class_name not in CLASS_LIST:\n",
    "                print(f'Добавление класса \"{class_name}\"')\n",
    "                CLASS_LIST.append(class_name)\n",
    "\n",
    "                # Инициализируем соответствующих классу строки текста\n",
    "                text_train.append('')\n",
    "                text_test.append('')\n",
    "\n",
    "            # Найдем индекс класса для добавления содержимого файла в выборку\n",
    "            cls = CLASS_LIST.index(class_name)\n",
    "            print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\", {subset_name} выборка.')\n",
    "\n",
    "            # Откроем файл на чтение  \n",
    "            with open(f'{FILE_DIR}/{file_name}', 'r') as f:  \n",
    "\n",
    "                # Загрузим содержимого файла в строку\n",
    "                text = f.read()\n",
    "            # Определим выборку, куда будет добавлено содержимое\n",
    "            subset = text_train if is_train else text_test\n",
    "\n",
    "            # Добавим текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
    "            subset[cls] += ' ' + text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoBX2ue9zJAF",
    "outputId": "0decc974-4ec4-4f8d-f775-f4b2c77fcee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Определим количество классов\n",
    "CLASS_COUNT = len(CLASS_LIST)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWh4j3HWzK6y",
    "outputId": "78b308f1-5e01-4f47-ebae-fa65865d8de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Клиффорд_Саймак', 'Макс Фрай', 'Стругацкие', 'О. Генри', 'Рэй Брэдберри', 'Булгаков']\n"
     ]
    }
   ],
   "source": [
    "# Выведем прочитанные классы текстов\n",
    "print(CLASS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GayHNBCCzMg-",
    "outputId": "037a1578-5634-4069-92fb-68e31be0c984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем количество текстов в обучающей выборке\n",
    "print(len(text_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MOn2laWQGwq",
    "outputId": "67dc5ed0-3905-4933-9839-c64bbc692e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс: Клиффорд_Саймак\n",
      "  train:  ﻿Всё живое...     Когда я выехал из нашего городишка и повернул на шоссе, позади оказался грузовик. Этакая тяжелая громадина с прицепом, и неслась она во весь дух. Шоссе здесь срезает угол городка, и\n",
      "  test :  ﻿Зачарованное паломничество    1  Гоблин со стропил следил за прячущимся монахом, который шпионил за ученым. Гоблин ненавидел монаха и имел для этого все основания. Монах никого не ненавидел и не люб\n",
      "\n",
      "Класс: Макс Фрай\n",
      "  train:  ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежедневно снится какая-то дичь! – сердито сказал я Джуффину. – Сглазили они меня, что ли? А собственно, по\n",
      "  test :  ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, ответ на закономерный вопрос: «Как меня сюда занесло?» – вряд ли принесёт практическую пользу. Зато пои\n",
      "\n",
      "Класс: Стругацкие\n",
      "  train:  Парень из преисподней     1     Ну и деревня! Сроду я таких деревень не видел и не знал даже, что такие деревни бывают. Дома круглые, бурые, без окон, торчат на сваях, как сторожевые вышки, а под ним\n",
      "  test :  ﻿ОТЕЛЬ «У ПОГИБШЕГО АЛЬПИНИСТА»    ГЛАВА 1     Я остановил машину, вылез и снял черные очки. Все было так, как рассказывал Згут. Отель был двухэтажный, желтый с зеленым, над крыльцом красовалась трау\n",
      "\n",
      "Класс: О. Генри\n",
      "  train:  «Лиса-на-рассвете»   Коралио нежился в полуденном зное, как томная красавица в сурово хранимом гареме. Город лежал у самого моря на полоске наносной земли. Он казался брильянтиком, вкрапленным в ярко\n",
      "  test :  ﻿Багдадская птица   Без всякого сомнения, дух и гений калифа Гаруна аль-Рашида осенил маркграфа Августа-Михаила фон Паульсена Квигга.  Ресторан Квигга находится на Четвертой авеню — на улице, которую\n",
      "\n",
      "Класс: Рэй Брэдберри\n",
      "  train:  ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n",
      "  test :  ﻿Марсианские хроники   МОЕЙ ЖЕНЕ МАРГАРЕТ С ИСКРЕННЕЙ ЛЮБОВЬЮ   «Великое дело – способность удивляться, – сказал философ. – Космические полеты снова сделали всех нас детьми».   Январь 1999  Ракетное \n",
      "\n",
      "Класс: Булгаков\n",
      "  train:  ﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил хло-  пьями. Ветер завыл; сделалась метель.  В одно мгновение темное небо смешалось с  снежным мор\n",
      "  test :  ﻿Дон Кихот ДЕЙСТВУЮЩИЕ ЛИЦА Алонсо Кихано, он же Дон Кихот Ламанчский.  Антония – его племянница.  Ключница Дон Кихота.  Санчо Панса – оруженосец Дон Кихота.  Перо Перес – деревенский священник, лице\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверим загрузки: выведем начальные отрывки из каждого класса\n",
    "\n",
    "for cls in range(CLASS_COUNT):                   # Запустим цикл по числу классов\n",
    "    print(f'Класс: {CLASS_LIST[cls]}')           # Выведем имя класса\n",
    "    print(f'  train: {text_train[cls][:200]}')   # Выведем фрагмент обучающей выборки\n",
    "    print(f'  test : {text_test[cls][:200]}')    # Выведем фрагмент тестовой выборки\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y2FgTG41QKaT"
   },
   "outputs": [],
   "source": [
    "# Контекстный менеджер для измерения времени операций\n",
    "# Операция обертывается менеджером с помощью оператора with\n",
    "\n",
    "class timex:\n",
    "    def __enter__(self):\n",
    "        # Фиксация времени старта процесса\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        # Вывод времени работы\n",
    "        print('Время обработки: {:.2f} с'.format(time.time() - self.t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSqt4mshIKzf"
   },
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LP8G65N-_36M"
   },
   "outputs": [],
   "source": [
    "# Токенизация и построение частотного словаря по обучающим текстам\n",
    "def build_vocab(text_list, vocab_size=10000):\n",
    "  with timex():\n",
    "      # Используется встроенный в Keras токенизатор для разбиения текста и построения частотного словаря\n",
    "      tokenizer = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token='неизвестное_слово', char_level=False)\n",
    "\n",
    "      # Использованы параметры:\n",
    "      # num_words   - объем словаря\n",
    "      # filters     - убираемые из текста ненужные символы\n",
    "      # lower       - приведение слов к нижнему регистру\n",
    "      # split       - разделитель слов\n",
    "      # char_level  - указание разделять по словам, а не по единичным символам\n",
    "      # oov_token   - токен для слов, которые не вошли в словарь\n",
    "\n",
    "      # Построение частотного словаря по обучающим текстам\n",
    "      tokenizer.fit_on_texts(text_list)\n",
    "      \n",
    "      # Построение словаря в виде пар слово - индекс\n",
    "      vocab = list(tokenizer.word_index.items())\n",
    "\n",
    "      # \n",
    "      seq = tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "      print(\"STATISTICS\")\n",
    "        # Вывод нескольких наиболее часто встречающихся слов\n",
    "      print(vocab[:120])\n",
    "      # Размер словаря может быть больше, чем num_words, но при преобразовании в последовательности\n",
    "      # и векторы bag of words будут учтены только первые num_words слов\n",
    "      print(\"Размер словаря\", len(vocab)) \n",
    "      print(\"Фрагмент обучающего текста:\")\n",
    "      print(\"  В виде оригинального текста:              \", text_list[1][:101])\n",
    "      print(\"  Он же в виде последовательности индексов: \", seq[1][:20])\n",
    "\n",
    "  return vocab, seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88VLjSa1bFvL"
   },
   "source": [
    "### Проверка функции build_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_V7M779fcQu",
    "outputId": "8bc1db51-fc5a-4b09-950e-d71302f70928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "STATISTICS\n",
      "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('я', 5), ('что', 6), ('на', 7), ('с', 8), ('он', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('все', 15), ('у', 16), ('по', 17), ('его', 18), ('к', 19), ('так', 20), ('мне', 21), ('из', 22), ('за', 23), ('меня', 24), ('ты', 25), ('же', 26), ('бы', 27), ('сказал', 28), ('вы', 29), ('было', 30), ('от', 31), ('они', 32), ('мы', 33), ('только', 34), ('да', 35), ('еще', 36), ('она', 37), ('о', 38), ('вот', 39), ('когда', 40), ('если', 41), ('уже', 42), ('был', 43), ('нет', 44), ('ни', 45), ('их', 46), ('ну', 47), ('чтобы', 48), ('до', 49), ('для', 50), ('ему', 51), ('ничего', 52), ('может', 53), ('или', 54), ('даже', 55), ('там', 56), ('очень', 57), ('кто', 58), ('ее', 59), ('тут', 60), ('потом', 61), ('просто', 62), ('чем', 63), ('него', 64), ('быть', 65), ('теперь', 66), ('под', 67), ('где', 68), ('нас', 69), ('есть', 70), ('тебя', 71), ('ли', 72), ('время', 73), ('тебе', 74), ('вас', 75), ('со', 76), ('нибудь', 77), ('во', 78), ('раз', 79), ('этот', 80), ('сейчас', 81), ('вам', 82), ('себя', 83), ('здесь', 84), ('себе', 85), ('этого', 86), ('надо', 87), ('уж', 88), ('будет', 89), ('том', 90), ('можно', 91), ('сам', 92), ('нам', 93), ('были', 94), ('была', 95), ('тоже', 96), ('того', 97), ('один', 98), ('без', 99), ('спросил', 100), ('больше', 101), ('них', 102), ('через', 103), ('ведь', 104), ('человек', 105), ('знаю', 106), ('этом', 107), ('конечно', 108), ('какой', 109), ('почему', 110), ('дело', 111), ('пока', 112), ('глаза', 113), ('андрей', 114), ('потому', 115), ('чего', 116), ('им', 117), ('несколько', 118), ('при', 119), ('совершенно', 120)]\n",
      "Размер словаря 133070\n",
      "Фрагмент обучающего текста:\n",
      "  В виде оригинального текста:                ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежеднев\n",
      "  Он же в виде последовательности индексов:  [1502, 1, 8, 282, 236, 11, 24, 9867, 6101, 3, 144, 7809, 1, 21, 3652, 12831, 238, 12, 19819, 1302]\n",
      "Время обработки: 6.03 с\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN')\n",
    "vocab_train, seq_train = build_vocab(text_train, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvcVaQlVffZW",
    "outputId": "34f4a562-4682-4b64-b850-30b961da2bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "STATISTICS\n",
      "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('на', 5), ('я', 6), ('что', 7), ('он', 8), ('с', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('его', 15), ('у', 16), ('по', 17), ('к', 18), ('из', 19), ('за', 20), ('все', 21), ('вы', 22), ('так', 23), ('же', 24), ('мне', 25), ('меня', 26), ('ты', 27), ('сказал', 28), ('было', 29), ('бы', 30), ('она', 31), ('от', 32), ('они', 33), ('мы', 34), ('только', 35), ('да', 36), ('о', 37), ('вот', 38), ('уже', 39), ('когда', 40), ('нет', 41), ('если', 42), ('был', 43), ('еще', 44), ('чтобы', 45), ('их', 46), ('ни', 47), ('ну', 48), ('до', 49), ('ему', 50), ('тут', 51), ('даже', 52), ('ее', 53), ('там', 54), ('для', 55), ('или', 56), ('под', 57), ('очень', 58), ('него', 59), ('может', 60), ('кто', 61), ('ничего', 62), ('где', 63), ('вас', 64), ('всё', 65), ('потом', 66), ('ли', 67), ('просто', 68), ('чем', 69), ('быть', 70), ('есть', 71), ('теперь', 72), ('вам', 73), ('время', 74), ('вилли', 75), ('раз', 76), ('со', 77), ('себя', 78), ('этого', 79), ('нас', 80), ('во', 81), ('здесь', 82), ('сейчас', 83), ('надо', 84), ('нибудь', 85), ('этот', 86), ('тебя', 87), ('будет', 88), ('этом', 89), ('человек', 90), ('тебе', 91), ('один', 92), ('спросил', 93), ('была', 94), ('можно', 95), ('себе', 96), ('глаза', 97), ('того', 98), ('больше', 99), ('тоже', 100), ('через', 101), ('были', 102), ('почему', 103), ('конечно', 104), ('без', 105), ('пока', 106), ('потому', 107), ('сам', 108), ('них', 109), ('том', 110), ('ведь', 111), ('ним', 112), ('тогда', 113), ('знаю', 114), ('джим', 115), ('какой', 116), ('совершенно', 117), ('при', 118), ('дело', 119), ('ещё', 120)]\n",
      "Размер словаря 82024\n",
      "Фрагмент обучающего текста:\n",
      "  В виде оригинального текста:                ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, отве\n",
      "  Он же в виде последовательности индексов:  [260, 164, 3403, 40, 1, 127, 10699, 5, 6438, 15206, 32, 1348, 5566, 493, 5, 1, 340, 11, 26, 203]\n",
      "Время обработки: 2.42 с\n"
     ]
    }
   ],
   "source": [
    "print('TEST')\n",
    "vocab_test, seq_test = build_vocab(text_test, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRWut34ycv9V"
   },
   "source": [
    "## Статистика по текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZaFByGZcjAJ",
    "outputId": "335f622f-0399-4824-c8c0-c9f441e04083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистика по обучающим текстам:\n",
      "Клиффорд_Саймак   1609508 символов,  251502 слов\n",
      "Макс Фрай         3700011 символов,  568533 слов\n",
      "Стругацкие        2042470 символов,  313012 слов\n",
      "О. Генри          1049518 символов,  160607 слов\n",
      "Рэй Брэдберри     1386455 символов,  214454 слов\n",
      "Булгаков          1765649 символов,  261465 слов\n",
      "----\n",
      "В сумме          11553611 символов, 1769573 слов\n",
      "\n",
      "Статистика по тестовым текстам:\n",
      "Клиффорд_Саймак    318812 символов,   50360 слов\n",
      "Макс Фрай         1278192 символов,  196731 слов\n",
      "Стругацкие         704847 символов,  108621 слов\n",
      "О. Генри           349663 символов,   53238 слов\n",
      "Рэй Брэдберри      868674 символов,  132524 слов\n",
      "Булгаков           875043 символов,  132730 слов\n",
      "----\n",
      "В сумме           4395231 символов,  674204 слов\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Функция вывода статистики по текстам\n",
    "def print_text_stats(title, texts, sequences, class_labels=CLASS_LIST):\n",
    "    # Суммарное количество символов и слов в тексте\n",
    "    chars = 0\n",
    "    words = 0\n",
    "\n",
    "    print(f'Статистика по {title} текстам:')\n",
    "\n",
    "    # Вывод итогов по всем классам данного набора текстов и их последовательностей индексов\n",
    "    for cls in range(len(class_labels)):\n",
    "        print('{:<15} {:9} символов,{:8} слов'.format(class_labels[cls],\n",
    "                                                      len(texts[cls]),\n",
    "                                                      len(sequences[cls])))\n",
    "        chars += len(texts[cls])\n",
    "        words += len(sequences[cls])\n",
    "\n",
    "    print('----')\n",
    "    print('{:<15} {:9} символов,{:8} слов\\n'.format('В сумме', chars, words))\n",
    "\n",
    "# Вывод итогов по текстам\n",
    "print_text_stats('обучающим', text_train, seq_train)\n",
    "print_text_stats('тестовым', text_test, seq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4iz75qvsoH9"
   },
   "source": [
    "## Функции формирования выборки\n",
    "\n",
    "sequence – последовательность индексов;  \n",
    "win_size – размер окна;  \n",
    "hop – шаг окна.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8cUXVx0EsukB"
   },
   "outputs": [],
   "source": [
    "# Функция разбиения последовательности на отрезки скользящим окном\n",
    "# На входе - последовательность индексов, размер окна, шаг окна\n",
    "def split_sequence(sequence, win_size, hop):\n",
    "    # Последовательность разбивается на части до последнего полного окна\n",
    "    return [sequence[i:i + win_size] for i in range(0, len(sequence) - win_size + 1, hop)]\n",
    "\n",
    "\n",
    "# Функция формирования выборок из последовательностей индексов\n",
    "# формирует выборку отрезков и соответствующих им меток классов в виде one hot encoding\n",
    "def vectorize_sequence(seq_list, win_size, hop):\n",
    "    # В списке последовательности следуют в порядке их классов\n",
    "    # Всего последовательностей в списке ровно столько, сколько классов\n",
    "    class_count = len(seq_list)\n",
    "\n",
    "    # Списки для исходных векторов и категориальных меток класса\n",
    "    x, y = [], []\n",
    "\n",
    "    # Для каждого класса:\n",
    "    for cls in range(class_count):\n",
    "        # Разбиение последовательности класса cls на отрезки\n",
    "        vectors = split_sequence(seq_list[cls], win_size, hop)\n",
    "        # Добавление отрезков в выборку\n",
    "        x += vectors\n",
    "        # Для всех отрезков класса cls добавление меток класса в виде OHE\n",
    "        y += [utils.to_categorical(cls, class_count)] * len(vectors)\n",
    "\n",
    "    # Возврат результатов как numpy-массивов\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X75jFt7stY86"
   },
   "source": [
    "## Функции для модели (из-зи ограничений ресурсов убираю всё лишнее)\n",
    "\n",
    "Напишите три уже стандартные функции:\n",
    "\n",
    "первая – создание, компиляция, обучение и вывод статистики по модели;\n",
    "вторая – вывод результатов оценки модели;\n",
    "третья – функция, объединяющая первую и вторую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0ZUvoGM2teXl"
   },
   "outputs": [],
   "source": [
    "# Функция компиляции и обучения модели нейронной сети\n",
    "def compile_train_model(model, \n",
    "                        x_train,\n",
    "                        y_train,\n",
    "                        x_val,\n",
    "                        y_val,\n",
    "                        optimizer='adam',\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        figsize=(20, 5)):\n",
    "\n",
    "    # Компиляция модели\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Вывод сводки\n",
    "    # model.summary()\n",
    "\n",
    "    # Вывод схемы модели\n",
    "    # display(plot_model(model, dpi=60, show_shapes=True))\n",
    "\n",
    "    # Обучение модели с заданными параметрами\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_val, y_val))\n",
    "\n",
    "    # Вывод графиков точности и ошибки\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    # fig.suptitle('График процесса обучения модели')\n",
    "    # ax1.plot(history.history['accuracy'], \n",
    "    #            label='Доля верных ответов на обучающем наборе')\n",
    "    # ax1.plot(history.history['val_accuracy'], \n",
    "    #            label='Доля верных ответов на проверочном наборе')\n",
    "    # ax1.xaxis.get_major_locator().set_params(integer=True)\n",
    "    # ax1.set_xlabel('Эпоха обучения')\n",
    "    # ax1.set_ylabel('Доля верных ответов')\n",
    "    # ax1.legend()\n",
    "\n",
    "    # ax2.plot(history.history['loss'], \n",
    "    #            label='Ошибка на обучающем наборе')\n",
    "    # ax2.plot(history.history['val_loss'], \n",
    "    #            label='Ошибка на проверочном наборе')\n",
    "    # ax2.xaxis.get_major_locator().set_params(integer=True)\n",
    "    # ax2.set_xlabel('Эпоха обучения')\n",
    "    # ax2.set_ylabel('Ошибка')\n",
    "    # ax2.legend()\n",
    "    # plt.show()\n",
    "\n",
    "# Функция вывода результатов оценки модели на заданных данных\n",
    "def eval_model(model, x, y_true,\n",
    "               class_labels=[],\n",
    "               cm_round=3,\n",
    "               title='',\n",
    "               figsize=(10, 10)):\n",
    "    # Вычисление предсказания сети\n",
    "    y_pred = model.predict(x)\n",
    "    # Построение матрицы ошибок\n",
    "    cm = confusion_matrix(np.argmax(y_true, axis=1),\n",
    "                          np.argmax(y_pred, axis=1),\n",
    "                          normalize='true')\n",
    "    # Округление значений матрицы ошибок\n",
    "    cm = np.around(cm, cm_round)\n",
    "\n",
    "    # Отрисовка матрицы ошибок\n",
    "    # fig, ax = plt.subplots(figsize=figsize)\n",
    "    # ax.set_title(f'Нейросеть {title}: матрица ошибок нормализованная', fontsize=18)\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    # disp.plot(ax=ax)\n",
    "    # plt.gca().images[-1].colorbar.remove()  # Стирание ненужной цветовой шкалы\n",
    "    # plt.xlabel('Предсказанные классы', fontsize=16)\n",
    "    # plt.ylabel('Верные классы', fontsize=16)\n",
    "    # fig.autofmt_xdate(rotation=45)          # Наклон меток горизонтальной оси при необходимости\n",
    "    # plt.show()    \n",
    "\n",
    "    print('-'*100)\n",
    "    print(f'Нейросеть: {title}')\n",
    "\n",
    "    # Для каждого класса:\n",
    "    for cls in range(len(class_labels)):\n",
    "        # Определяется индекс класса с максимальным значением предсказания (уверенности)\n",
    "        cls_pred = np.argmax(cm[cls])\n",
    "        # Формируется сообщение о верности или неверности предсказания\n",
    "        msg = 'ВЕРНО :-)' if cls_pred == cls else 'НЕВЕРНО :-('\n",
    "        # Выводится текстовая информация о предсказанном классе и значении уверенности\n",
    "        print('Класс: {:<20} {:3.0f}% сеть отнесла к классу {:<20} - {}'.format(class_labels[cls],\n",
    "                                                                               100. * cm[cls, cls_pred],\n",
    "                                                                               class_labels[cls_pred],\n",
    "                                                                               msg))\n",
    "    avg_accuracy = 100. * cm.diagonal().mean()\n",
    "    # Средняя точность распознавания определяется как среднее диагональных элементов матрицы ошибок\n",
    "    print('\\nСредняя точность распознавания: {:3.0f}%'.format(avg_accuracy))\n",
    "    return avg_accuracy\n",
    "\n",
    "\n",
    "# Совместная функция обучения и оценки модели нейронной сети\n",
    "def compile_train_eval_model(model, \n",
    "                             x_train,\n",
    "                             y_train,\n",
    "                             x_test,\n",
    "                             y_test,\n",
    "                             class_labels=CLASS_LIST,\n",
    "                             title='',\n",
    "                             optimizer='adam',\n",
    "                             epochs=50,\n",
    "                             batch_size=128,\n",
    "                             graph_size=(20, 5),\n",
    "                             cm_size=(10, 10)):\n",
    "\n",
    "    # Компиляция и обучение модели на заданных параметрах\n",
    "    # В качестве проверочных используются тестовые данные\n",
    "    compile_train_model(model, \n",
    "                        x_train, y_train,\n",
    "                        x_test, y_test,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        figsize=graph_size)\n",
    "\n",
    "    # Вывод результатов оценки работы модели на тестовых данных\n",
    "    avg_accuracy = eval_model(model, x_test, y_test, \n",
    "               class_labels=class_labels, \n",
    "               title=title,\n",
    "               figsize=cm_size)\n",
    "    \n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CA9JYNagxqY4"
   },
   "source": [
    "## Основной цикл для модели №13: Embedding(50) + BLSTM(8)x2 + GRU(16)x2 + Dense(200)\n",
    "\n",
    "Подготовьте датасет с параметрами VOCAB_SIZE=20'000, WIN_SIZE=1000, WIN_HOP=100, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
    "Поменяйте размер словаря tokenaizera (VOCAB_SIZE) на 5000, 10000, 40000. Пересоздайте датасеты, при этом оставьте WIN_SIZE=1000, WIN_HOP=100. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об изменении точности распознавания авторов текстов. Результаты сведите в таблицу\n",
    "Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы (WIN_SIZE, WIN_HOP) используя значения (500,50) и (2000,200). Пересоздайте датасеты, при этом оставьте VOCAB_SIZE=20000. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об изменении точности распознавания авторов текстов.\n",
    "Результаты всей работы сведите в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2NHpn5PDyR0L",
    "outputId": "d533ada4-703d-46f1-b8e3-5017ffefe3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTICS\n",
      "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('я', 5), ('что', 6), ('на', 7), ('с', 8), ('он', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('все', 15), ('у', 16), ('по', 17), ('его', 18), ('к', 19), ('так', 20), ('мне', 21), ('из', 22), ('за', 23), ('меня', 24), ('ты', 25), ('же', 26), ('бы', 27), ('сказал', 28), ('вы', 29), ('было', 30), ('от', 31), ('они', 32), ('мы', 33), ('только', 34), ('да', 35), ('еще', 36), ('она', 37), ('о', 38), ('вот', 39), ('когда', 40), ('если', 41), ('уже', 42), ('был', 43), ('нет', 44), ('ни', 45), ('их', 46), ('ну', 47), ('чтобы', 48), ('до', 49), ('для', 50), ('ему', 51), ('ничего', 52), ('может', 53), ('или', 54), ('даже', 55), ('там', 56), ('очень', 57), ('кто', 58), ('ее', 59), ('тут', 60), ('потом', 61), ('просто', 62), ('чем', 63), ('него', 64), ('быть', 65), ('теперь', 66), ('под', 67), ('где', 68), ('нас', 69), ('есть', 70), ('тебя', 71), ('ли', 72), ('время', 73), ('тебе', 74), ('вас', 75), ('со', 76), ('нибудь', 77), ('во', 78), ('раз', 79), ('этот', 80), ('сейчас', 81), ('вам', 82), ('себя', 83), ('здесь', 84), ('себе', 85), ('этого', 86), ('надо', 87), ('уж', 88), ('будет', 89), ('том', 90), ('можно', 91), ('сам', 92), ('нам', 93), ('были', 94), ('была', 95), ('тоже', 96), ('того', 97), ('один', 98), ('без', 99), ('спросил', 100), ('больше', 101), ('них', 102), ('через', 103), ('ведь', 104), ('человек', 105), ('знаю', 106), ('этом', 107), ('конечно', 108), ('какой', 109), ('почему', 110), ('дело', 111), ('пока', 112), ('глаза', 113), ('андрей', 114), ('потому', 115), ('чего', 116), ('им', 117), ('несколько', 118), ('при', 119), ('совершенно', 120)]\n",
      "Размер словаря 133070\n",
      "Фрагмент обучающего текста:\n",
      "  В виде оригинального текста:                ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежеднев\n",
      "  Он же в виде последовательности индексов:  [1502, 1, 8, 282, 236, 11, 24, 1, 1, 3, 144, 1, 1, 21, 3652, 1, 238, 12, 1, 1302]\n",
      "Время обработки: 7.15 с\n",
      "STATISTICS\n",
      "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('на', 5), ('я', 6), ('что', 7), ('он', 8), ('с', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('его', 15), ('у', 16), ('по', 17), ('к', 18), ('из', 19), ('за', 20), ('все', 21), ('вы', 22), ('так', 23), ('же', 24), ('мне', 25), ('меня', 26), ('ты', 27), ('сказал', 28), ('было', 29), ('бы', 30), ('она', 31), ('от', 32), ('они', 33), ('мы', 34), ('только', 35), ('да', 36), ('о', 37), ('вот', 38), ('уже', 39), ('когда', 40), ('нет', 41), ('если', 42), ('был', 43), ('еще', 44), ('чтобы', 45), ('их', 46), ('ни', 47), ('ну', 48), ('до', 49), ('ему', 50), ('тут', 51), ('даже', 52), ('ее', 53), ('там', 54), ('для', 55), ('или', 56), ('под', 57), ('очень', 58), ('него', 59), ('может', 60), ('кто', 61), ('ничего', 62), ('где', 63), ('вас', 64), ('всё', 65), ('потом', 66), ('ли', 67), ('просто', 68), ('чем', 69), ('быть', 70), ('есть', 71), ('теперь', 72), ('вам', 73), ('время', 74), ('вилли', 75), ('раз', 76), ('со', 77), ('себя', 78), ('этого', 79), ('нас', 80), ('во', 81), ('здесь', 82), ('сейчас', 83), ('надо', 84), ('нибудь', 85), ('этот', 86), ('тебя', 87), ('будет', 88), ('этом', 89), ('человек', 90), ('тебе', 91), ('один', 92), ('спросил', 93), ('была', 94), ('можно', 95), ('себе', 96), ('глаза', 97), ('того', 98), ('больше', 99), ('тоже', 100), ('через', 101), ('были', 102), ('почему', 103), ('конечно', 104), ('без', 105), ('пока', 106), ('потому', 107), ('сам', 108), ('них', 109), ('том', 110), ('ведь', 111), ('ним', 112), ('тогда', 113), ('знаю', 114), ('джим', 115), ('какой', 116), ('совершенно', 117), ('при', 118), ('дело', 119), ('ещё', 120)]\n",
      "Размер словаря 82024\n",
      "Фрагмент обучающего текста:\n",
      "  В виде оригинального текста:                ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, отве\n",
      "  Он же в виде последовательности индексов:  [260, 164, 3403, 40, 1, 127, 1, 5, 1, 1, 32, 1348, 1, 493, 5, 1, 340, 11, 26, 203]\n",
      "Время обработки: 2.53 с\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=100\n",
      "(17696, 50) (17696, 6)\n",
      "(6741, 50) (6741, 6)\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 12s 183ms/step - loss: 2.0360 - accuracy: 0.2076 - val_loss: 1.7371 - val_accuracy: 0.2918\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 7s 196ms/step - loss: 1.8650 - accuracy: 0.2663 - val_loss: 1.7449 - val_accuracy: 0.2918\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 1.7634 - accuracy: 0.3119 - val_loss: 1.7509 - val_accuracy: 0.2918\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 7s 194ms/step - loss: 1.6651 - accuracy: 0.3521 - val_loss: 1.7659 - val_accuracy: 0.2918\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 5s 156ms/step - loss: 1.5188 - accuracy: 0.4134 - val_loss: 1.8250 - val_accuracy: 0.2912\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 7s 196ms/step - loss: 1.3095 - accuracy: 0.4937 - val_loss: 1.9648 - val_accuracy: 0.1831\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 1.1525 - accuracy: 0.5598 - val_loss: 2.1144 - val_accuracy: 0.2244\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 1.0176 - accuracy: 0.6103 - val_loss: 2.2191 - val_accuracy: 0.0964\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 5s 157ms/step - loss: 0.9085 - accuracy: 0.6586 - val_loss: 2.4037 - val_accuracy: 0.1860\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 7s 195ms/step - loss: 0.8018 - accuracy: 0.7071 - val_loss: 2.3244 - val_accuracy: 0.1222\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 0.7158 - accuracy: 0.7429 - val_loss: 2.4268 - val_accuracy: 0.1248\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 7s 192ms/step - loss: 0.6263 - accuracy: 0.7753 - val_loss: 2.7998 - val_accuracy: 0.1905\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 6s 157ms/step - loss: 0.5569 - accuracy: 0.8063 - val_loss: 2.8804 - val_accuracy: 0.1792\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 6s 182ms/step - loss: 0.4997 - accuracy: 0.8249 - val_loss: 3.1007 - val_accuracy: 0.1610\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 6s 164ms/step - loss: 0.4575 - accuracy: 0.8444 - val_loss: 3.7879 - val_accuracy: 0.2010\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 6s 163ms/step - loss: 0.4187 - accuracy: 0.8590 - val_loss: 3.9634 - val_accuracy: 0.1880\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 0.3850 - accuracy: 0.8703 - val_loss: 4.2228 - val_accuracy: 0.1897\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 0.3535 - accuracy: 0.8828 - val_loss: 4.7900 - val_accuracy: 0.1853\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 7s 192ms/step - loss: 0.3321 - accuracy: 0.8869 - val_loss: 4.7610 - val_accuracy: 0.1779\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 6s 157ms/step - loss: 0.3120 - accuracy: 0.8953 - val_loss: 4.9710 - val_accuracy: 0.1926\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 7s 191ms/step - loss: 0.2840 - accuracy: 0.9075 - val_loss: 5.2714 - val_accuracy: 0.1977\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 5s 156ms/step - loss: 0.2720 - accuracy: 0.9080 - val_loss: 5.5759 - val_accuracy: 0.1888\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 7s 192ms/step - loss: 0.2527 - accuracy: 0.9171 - val_loss: 5.5206 - val_accuracy: 0.1903\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 5s 154ms/step - loss: 0.2364 - accuracy: 0.9210 - val_loss: 5.6146 - val_accuracy: 0.1934\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 7s 190ms/step - loss: 0.2234 - accuracy: 0.9259 - val_loss: 5.9068 - val_accuracy: 0.1991\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 0.2056 - accuracy: 0.9328 - val_loss: 5.9198 - val_accuracy: 0.1970\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 7s 190ms/step - loss: 0.2094 - accuracy: 0.9307 - val_loss: 6.0585 - val_accuracy: 0.1949\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 0.2050 - accuracy: 0.9316 - val_loss: 6.0522 - val_accuracy: 0.1819\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 7s 198ms/step - loss: 0.1817 - accuracy: 0.9416 - val_loss: 6.1196 - val_accuracy: 0.1877\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 0.1697 - accuracy: 0.9449 - val_loss: 6.7225 - val_accuracy: 0.2055\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 7s 195ms/step - loss: 0.1656 - accuracy: 0.9450 - val_loss: 6.7905 - val_accuracy: 0.1994\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 6s 160ms/step - loss: 0.1568 - accuracy: 0.9486 - val_loss: 6.5238 - val_accuracy: 0.1834\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 6s 177ms/step - loss: 0.1514 - accuracy: 0.9503 - val_loss: 6.6658 - val_accuracy: 0.1988\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 6s 168ms/step - loss: 0.1429 - accuracy: 0.9526 - val_loss: 6.9250 - val_accuracy: 0.1894\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 6s 185ms/step - loss: 0.1389 - accuracy: 0.9528 - val_loss: 6.8049 - val_accuracy: 0.1860\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 6s 172ms/step - loss: 0.1398 - accuracy: 0.9532 - val_loss: 6.8537 - val_accuracy: 0.1980\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 6s 173ms/step - loss: 0.1322 - accuracy: 0.9548 - val_loss: 7.0423 - val_accuracy: 0.1853\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 6s 181ms/step - loss: 0.1219 - accuracy: 0.9593 - val_loss: 7.0906 - val_accuracy: 0.1813\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 6s 167ms/step - loss: 0.1120 - accuracy: 0.9629 - val_loss: 7.3841 - val_accuracy: 0.1798\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 7s 191ms/step - loss: 0.1128 - accuracy: 0.9626 - val_loss: 7.2532 - val_accuracy: 0.1952\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 6s 164ms/step - loss: 0.1137 - accuracy: 0.9619 - val_loss: 7.1684 - val_accuracy: 0.2015\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 7s 198ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 7.2349 - val_accuracy: 0.1937\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 6s 159ms/step - loss: 0.1073 - accuracy: 0.9651 - val_loss: 7.4733 - val_accuracy: 0.1943\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 7.6539 - val_accuracy: 0.2009\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 5s 155ms/step - loss: 0.0942 - accuracy: 0.9689 - val_loss: 7.3904 - val_accuracy: 0.2018\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 0.0946 - accuracy: 0.9690 - val_loss: 7.6320 - val_accuracy: 0.1841\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 6s 158ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: 7.8481 - val_accuracy: 0.1969\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 7s 195ms/step - loss: 0.0889 - accuracy: 0.9699 - val_loss: 7.8496 - val_accuracy: 0.2001\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 6s 161ms/step - loss: 0.0874 - accuracy: 0.9717 - val_loss: 7.8312 - val_accuracy: 0.1844\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 7s 195ms/step - loss: 0.0870 - accuracy: 0.9717 - val_loss: 7.9238 - val_accuracy: 0.1899\n",
      "211/211 [==============================] - 4s 13ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Нейросеть: Embedding(50) + BLSTM(8)x2 + GRU(16)x2 + Dense(200)\n",
      "Класс: Клиффорд_Саймак       39% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Макс Фрай             32% сеть отнесла к классу Макс Фрай            - ВЕРНО :-)\n",
      "Класс: Стругацкие            27% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: О. Генри              34% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Рэй Брэдберри         33% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Булгаков              33% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "\n",
      "Средняя точность распознавания:  17%\n",
      "Время обработки: 334.94 с\n",
      "5000;50;100;16.53333333333333\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=200\n",
      "(8850, 50) (8850, 6)\n",
      "(3372, 50) (3372, 6)\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 10s 230ms/step - loss: 2.1451 - accuracy: 0.1955 - val_loss: 1.7562 - val_accuracy: 0.2918\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 4s 203ms/step - loss: 1.9444 - accuracy: 0.2400 - val_loss: 1.7454 - val_accuracy: 0.2918\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 1.8901 - accuracy: 0.2699 - val_loss: 1.7449 - val_accuracy: 0.2918\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 1.8025 - accuracy: 0.3006 - val_loss: 1.7477 - val_accuracy: 0.2918\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 1.7246 - accuracy: 0.3315 - val_loss: 1.7477 - val_accuracy: 0.2918\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 4s 204ms/step - loss: 1.6557 - accuracy: 0.3614 - val_loss: 1.7474 - val_accuracy: 0.2918\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 1.5655 - accuracy: 0.3999 - val_loss: 1.7659 - val_accuracy: 0.2918\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 3s 159ms/step - loss: 1.4776 - accuracy: 0.4315 - val_loss: 1.7809 - val_accuracy: 0.2390\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 3s 161ms/step - loss: 1.3538 - accuracy: 0.4923 - val_loss: 1.8100 - val_accuracy: 0.1613\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 4s 206ms/step - loss: 1.2418 - accuracy: 0.5216 - val_loss: 1.8666 - val_accuracy: 0.1601\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 1.1346 - accuracy: 0.5677 - val_loss: 1.9387 - val_accuracy: 0.1563\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 3s 161ms/step - loss: 1.0518 - accuracy: 0.6001 - val_loss: 1.9984 - val_accuracy: 0.1631\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 3s 162ms/step - loss: 0.9624 - accuracy: 0.6363 - val_loss: 2.1200 - val_accuracy: 0.1302\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 4s 208ms/step - loss: 0.8889 - accuracy: 0.6697 - val_loss: 2.1274 - val_accuracy: 0.1590\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.8341 - accuracy: 0.6908 - val_loss: 2.3288 - val_accuracy: 0.1438\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 0.7747 - accuracy: 0.7104 - val_loss: 2.4059 - val_accuracy: 0.1593\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 3s 162ms/step - loss: 0.7196 - accuracy: 0.7299 - val_loss: 2.4932 - val_accuracy: 0.1610\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 4s 211ms/step - loss: 0.6654 - accuracy: 0.7551 - val_loss: 2.6807 - val_accuracy: 0.2002\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6266 - accuracy: 0.7710 - val_loss: 2.6795 - val_accuracy: 0.1732\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 0.5828 - accuracy: 0.7872 - val_loss: 2.8644 - val_accuracy: 0.1762\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 3s 163ms/step - loss: 0.5578 - accuracy: 0.8009 - val_loss: 2.9526 - val_accuracy: 0.1945\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 4s 204ms/step - loss: 0.5146 - accuracy: 0.8166 - val_loss: 2.9589 - val_accuracy: 0.1539\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.4912 - accuracy: 0.8262 - val_loss: 3.2304 - val_accuracy: 0.1753\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 3s 161ms/step - loss: 0.4628 - accuracy: 0.8382 - val_loss: 3.5176 - val_accuracy: 0.1916\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 0.4264 - accuracy: 0.8486 - val_loss: 3.3884 - val_accuracy: 0.1711\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 4s 210ms/step - loss: 0.4053 - accuracy: 0.8580 - val_loss: 3.6726 - val_accuracy: 0.1750\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.3830 - accuracy: 0.8650 - val_loss: 3.8378 - val_accuracy: 0.1776\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 0.3549 - accuracy: 0.8767 - val_loss: 4.0318 - val_accuracy: 0.1853\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 0.3260 - accuracy: 0.8834 - val_loss: 4.3558 - val_accuracy: 0.1833\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 4s 197ms/step - loss: 0.3104 - accuracy: 0.8928 - val_loss: 4.7412 - val_accuracy: 0.1999\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.3056 - accuracy: 0.8927 - val_loss: 4.9098 - val_accuracy: 0.2040\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 0.2839 - accuracy: 0.8999 - val_loss: 5.0865 - val_accuracy: 0.2026\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 3s 161ms/step - loss: 0.2631 - accuracy: 0.9085 - val_loss: 5.0989 - val_accuracy: 0.1966\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 4s 208ms/step - loss: 0.2336 - accuracy: 0.9192 - val_loss: 5.6295 - val_accuracy: 0.2037\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.2369 - accuracy: 0.9168 - val_loss: 5.4513 - val_accuracy: 0.1853\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 0.2191 - accuracy: 0.9259 - val_loss: 5.9469 - val_accuracy: 0.1960\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 3s 162ms/step - loss: 0.2214 - accuracy: 0.9273 - val_loss: 6.0956 - val_accuracy: 0.2079\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 4s 208ms/step - loss: 0.2042 - accuracy: 0.9281 - val_loss: 6.6540 - val_accuracy: 0.2233\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.1998 - accuracy: 0.9318 - val_loss: 6.0985 - val_accuracy: 0.2026\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.1802 - accuracy: 0.9386 - val_loss: 6.3492 - val_accuracy: 0.2091\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 3s 158ms/step - loss: 0.1673 - accuracy: 0.9433 - val_loss: 6.4617 - val_accuracy: 0.2005\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 3s 197ms/step - loss: 0.1579 - accuracy: 0.9447 - val_loss: 6.4908 - val_accuracy: 0.1981\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.1581 - accuracy: 0.9472 - val_loss: 6.9185 - val_accuracy: 0.2052\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 3s 159ms/step - loss: 0.1465 - accuracy: 0.9523 - val_loss: 6.8469 - val_accuracy: 0.2020\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 3s 164ms/step - loss: 0.1428 - accuracy: 0.9505 - val_loss: 6.8363 - val_accuracy: 0.1960\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.1432 - accuracy: 0.9516 - val_loss: 7.1803 - val_accuracy: 0.2159\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 4s 192ms/step - loss: 0.1373 - accuracy: 0.9548 - val_loss: 7.2121 - val_accuracy: 0.2100\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 0.1286 - accuracy: 0.9583 - val_loss: 7.0515 - val_accuracy: 0.2043\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 0.1305 - accuracy: 0.9557 - val_loss: 7.1074 - val_accuracy: 0.1928\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 4s 205ms/step - loss: 0.1093 - accuracy: 0.9644 - val_loss: 7.2265 - val_accuracy: 0.2008\n",
      "106/106 [==============================] - 2s 13ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Нейросеть: Embedding(50) + BLSTM(8)x2 + GRU(16)x2 + Dense(200)\n",
      "Класс: Клиффорд_Саймак       35% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Макс Фрай             29% сеть отнесла к классу Макс Фрай            - ВЕРНО :-)\n",
      "Класс: Стругацкие            25% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: О. Генри              28% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Рэй Брэдберри         32% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Булгаков              31% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "\n",
      "Средняя точность распознавания:  19%\n",
      "Время обработки: 211.85 с\n",
      "5000;50;200;18.566666666666663\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=2000\n",
      "(888, 50) (888, 6)\n",
      "(341, 50) (341, 6)\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 7s 1s/step - loss: 2.3770 - accuracy: 0.1824 - val_loss: 1.7759 - val_accuracy: 0.2903\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 2.1948 - accuracy: 0.1689 - val_loss: 1.7706 - val_accuracy: 0.2903\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 2.0726 - accuracy: 0.2128 - val_loss: 1.7653 - val_accuracy: 0.2903\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 2.0010 - accuracy: 0.2230 - val_loss: 1.7612 - val_accuracy: 0.2903\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 1.9014 - accuracy: 0.2455 - val_loss: 1.7584 - val_accuracy: 0.2903\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 1.9637 - accuracy: 0.2387 - val_loss: 1.7557 - val_accuracy: 0.2903\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 1.9189 - accuracy: 0.2849 - val_loss: 1.7530 - val_accuracy: 0.2903\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 1.8681 - accuracy: 0.2939 - val_loss: 1.7512 - val_accuracy: 0.2903\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 1.7892 - accuracy: 0.3288 - val_loss: 1.7494 - val_accuracy: 0.2903\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 1.7496 - accuracy: 0.3491 - val_loss: 1.7477 - val_accuracy: 0.2903\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 1.7176 - accuracy: 0.3412 - val_loss: 1.7465 - val_accuracy: 0.2903\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 1.7466 - accuracy: 0.3581 - val_loss: 1.7459 - val_accuracy: 0.2903\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 1.6332 - accuracy: 0.4043 - val_loss: 1.7453 - val_accuracy: 0.2903\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.6486 - accuracy: 0.3863 - val_loss: 1.7455 - val_accuracy: 0.2903\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 1.5452 - accuracy: 0.4234 - val_loss: 1.7461 - val_accuracy: 0.2903\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 1.5036 - accuracy: 0.4257 - val_loss: 1.7466 - val_accuracy: 0.2903\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 1.4636 - accuracy: 0.4561 - val_loss: 1.7459 - val_accuracy: 0.2903\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 1.4733 - accuracy: 0.4347 - val_loss: 1.7464 - val_accuracy: 0.2903\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 1.3921 - accuracy: 0.4786 - val_loss: 1.7471 - val_accuracy: 0.2903\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 297ms/step - loss: 1.3557 - accuracy: 0.4865 - val_loss: 1.7484 - val_accuracy: 0.2903\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 1.2663 - accuracy: 0.5259 - val_loss: 1.7496 - val_accuracy: 0.2903\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.2484 - accuracy: 0.5248 - val_loss: 1.7505 - val_accuracy: 0.2903\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.1826 - accuracy: 0.5619 - val_loss: 1.7512 - val_accuracy: 0.2903\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.1457 - accuracy: 0.5698 - val_loss: 1.7533 - val_accuracy: 0.2903\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.1477 - accuracy: 0.5698 - val_loss: 1.7560 - val_accuracy: 0.2903\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 1.1374 - accuracy: 0.5833 - val_loss: 1.7586 - val_accuracy: 0.2903\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 1.0415 - accuracy: 0.6261 - val_loss: 1.7605 - val_accuracy: 0.2903\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 1.0301 - accuracy: 0.6216 - val_loss: 1.7603 - val_accuracy: 0.2903\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.9975 - accuracy: 0.6250 - val_loss: 1.7649 - val_accuracy: 0.2903\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.8777 - accuracy: 0.6836 - val_loss: 1.7648 - val_accuracy: 0.2903\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.9425 - accuracy: 0.6430 - val_loss: 1.7672 - val_accuracy: 0.2903\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.8579 - accuracy: 0.6881 - val_loss: 1.7729 - val_accuracy: 0.2903\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.8226 - accuracy: 0.6847 - val_loss: 1.7752 - val_accuracy: 0.2903\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.8188 - accuracy: 0.7061 - val_loss: 1.7754 - val_accuracy: 0.2903\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.7606 - accuracy: 0.7320 - val_loss: 1.7750 - val_accuracy: 0.2903\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.7574 - accuracy: 0.7196 - val_loss: 1.7750 - val_accuracy: 0.2874\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 0.7163 - accuracy: 0.7444 - val_loss: 1.7765 - val_accuracy: 0.2698\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.6231 - accuracy: 0.7815 - val_loss: 1.7786 - val_accuracy: 0.2757\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.6520 - accuracy: 0.7658 - val_loss: 1.7766 - val_accuracy: 0.2698\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.6072 - accuracy: 0.7894 - val_loss: 1.7777 - val_accuracy: 0.2669\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.5604 - accuracy: 0.7827 - val_loss: 1.7773 - val_accuracy: 0.2698\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.5238 - accuracy: 0.8153 - val_loss: 1.7795 - val_accuracy: 0.2698\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 0.5232 - accuracy: 0.8029 - val_loss: 1.7853 - val_accuracy: 0.2082\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.4960 - accuracy: 0.8243 - val_loss: 1.7840 - val_accuracy: 0.2405\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.4432 - accuracy: 0.8367 - val_loss: 1.7884 - val_accuracy: 0.1994\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.4420 - accuracy: 0.8457 - val_loss: 1.7876 - val_accuracy: 0.2346\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.3971 - accuracy: 0.8592 - val_loss: 1.7860 - val_accuracy: 0.2669\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.3972 - accuracy: 0.8581 - val_loss: 1.7864 - val_accuracy: 0.2639\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.3609 - accuracy: 0.8739 - val_loss: 1.7845 - val_accuracy: 0.2727\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.3613 - accuracy: 0.8784 - val_loss: 1.7869 - val_accuracy: 0.2757\n",
      "11/11 [==============================] - 2s 20ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Нейросеть: Embedding(50) + BLSTM(8)x2 + GRU(16)x2 + Dense(200)\n",
      "Класс: Клиффорд_Саймак       96% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Макс Фрай             95% сеть отнесла к классу Макс Фрай            - ВЕРНО :-)\n",
      "Класс: Стругацкие           100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: О. Генри             100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Рэй Брэдберри         94% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "Класс: Булгаков             100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
      "\n",
      "Средняя точность распознавания:  16%\n",
      "Время обработки: 28.52 с\n",
      "5000;50;2000;15.816666666666665\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VOCAB_SIZE=5000; WIN_SIZE=500; WIN_HOP=100\n",
      "(17670, 500) (17670, 6)\n",
      "(6716, 500) (6716, 6)\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 68s 2s/step - loss: 2.0708 - accuracy: 0.2106 - val_loss: 1.7406 - val_accuracy: 0.2923\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 65s 2s/step - loss: 1.8886 - accuracy: 0.2585 - val_loss: 1.7434 - val_accuracy: 0.2923\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 62s 2s/step - loss: 1.7853 - accuracy: 0.3001 - val_loss: 1.7427 - val_accuracy: 0.2923\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 65s 2s/step - loss: 1.6908 - accuracy: 0.3372 - val_loss: 1.7453 - val_accuracy: 0.2923\n",
      "Epoch 5/50\n",
      "23/35 [==================>...........] - ETA: 19s - loss: 1.5776 - accuracy: 0.3892Время обработки: 301.70 с\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7430162e2db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmodel_LSTM_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASS_COUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         avg_accuracy = compile_train_eval_model(model_LSTM_6,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                 \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                 \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ea00c273f963>\u001b[0m in \u001b[0;36mcompile_train_eval_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, class_labels, title, optimizer, epochs, batch_size, graph_size, cm_size)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Компиляция и обучение модели на заданных параметрах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# В качестве проверочных используются тестовые данные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     compile_train_model(model, \n\u001b[0m\u001b[1;32m    115\u001b[0m                         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                         \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ea00c273f963>\u001b[0m in \u001b[0;36mcompile_train_model\u001b[0;34m(model, x_train, y_train, x_val, y_val, optimizer, epochs, batch_size, figsize)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Обучение модели с заданными параметрами\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     history = model.fit(x_train,\n\u001b[0m\u001b[1;32m     25\u001b[0m                         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns = ['VOCAB_SIZE', 'WIN_SIZE', 'WIN_HOP', 'avg_accuracy'])\n",
    "\n",
    "for VOCAB_SIZE in [5000, 10000, 20000, 40000]:\n",
    "  vocab_train, seq_train, vocab_test, seq_test = None, None, None, None\n",
    "  vocab_train, seq_train = build_vocab(text_train, VOCAB_SIZE)\n",
    "  vocab_test, seq_test = build_vocab(text_test, VOCAB_SIZE)\n",
    "  for WIN_SIZE in [50, 500, 1000]:\n",
    "    for WIN_HOP in [100, 200, 2000]:\n",
    "      print(3*\"\\n\")\n",
    "      print(80*\"=\")\n",
    "      print(f\"VOCAB_SIZE={VOCAB_SIZE}; WIN_SIZE={WIN_SIZE}; WIN_HOP={WIN_HOP}\")\n",
    "\n",
    "      x_train, y_train, x_test, y_test, model_LSTM_6 = None, None, None, None, None\n",
    "      # Формирование обучающей и тестовой выборок\n",
    "      # with timex():\n",
    "      # Формирование обучающей выборки\n",
    "      x_train, y_train = vectorize_sequence(seq_train, WIN_SIZE, WIN_HOP) \n",
    "      # Формирование тестовой выборки\n",
    "      x_test, y_test = vectorize_sequence(seq_test, WIN_SIZE, WIN_HOP)\n",
    "\n",
    "      # Проверка формы сформированных данных\n",
    "      print(x_train.shape, y_train.shape)\n",
    "      print(x_test.shape, y_test.shape)\n",
    "\n",
    "      # Создание модели\n",
    "      model_LSTM_6 = Sequential()\n",
    "      model_LSTM_6.add(Embedding(VOCAB_SIZE, 50, input_length=WIN_SIZE))\n",
    "      model_LSTM_6.add(SpatialDropout1D(0.4))\n",
    "      model_LSTM_6.add(BatchNormalization())\n",
    "      # Два двунаправленных рекуррентных слоя LSTM\n",
    "      # model_LSTM_6.add(Bidirectional(LSTM(8, return_sequences=True)))\n",
    "      # model_LSTM_6.add(Bidirectional(LSTM(8, return_sequences=True)))\n",
    "      # model_LSTM_6.add(Dropout(0.3))\n",
    "      # model_LSTM_6.add(BatchNormalization())\n",
    "      # Два рекуррентных слоя GRU\n",
    "      model_LSTM_6.add(GRU(16, return_sequences=True, reset_after=True))\n",
    "      model_LSTM_6.add(GRU(16, reset_after=True))\n",
    "      model_LSTM_6.add(Dropout(0.3))\n",
    "      model_LSTM_6.add(BatchNormalization())\n",
    "      # Дополнительный полносвязный слой\n",
    "      model_LSTM_6.add(Dense(200, activation='relu'))\n",
    "      model_LSTM_6.add(Dropout(0.3))\n",
    "      model_LSTM_6.add(BatchNormalization())\n",
    "      model_LSTM_6.add(Dense(CLASS_COUNT, activation='softmax'))\n",
    "\n",
    "      avg_accuracy = compile_train_eval_model(model_LSTM_6,\n",
    "                              x_train, y_train,\n",
    "                              x_test, y_test,\n",
    "                              optimizer='rmsprop',\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              class_labels=CLASS_LIST,\n",
    "                              title='mynet')\n",
    "      print(f\"{VOCAB_SIZE};{WIN_SIZE};{WIN_HOP};{avg_accuracy}\")\n",
    "      df = df.append({'VOCAB_SIZE' : VOCAB_SIZE, 'WIN_SIZE' : WIN_SIZE, 'WIN_HOP' : WIN_HOP, 'avg_accuracy' : avg_accuracy}, ignore_index = True)\n",
    "      df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZZR6nlXKqqs"
   },
   "source": [
    "## Результирующая таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPD2TlJzKvFG"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
