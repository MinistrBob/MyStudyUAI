{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinistrBob/MyStudyUAI/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D0%B8_%D0%BE%D0%B4%D0%BD%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D1%8B%D0%B5_%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%7C_%D0%94%D0%97_Lite_%7C_%D0%A3%D0%98%D0%98%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK4SSIkcMnDG"
      },
      "source": [
        "1. Из ноутбуков по практике \"Рекуррентные и одномерные сверточные нейронные сети\" выберите лучшую сеть, либо создайте свою. \n",
        "2. Запустите раздел \"Подготовка\"\n",
        "3. Подготовьте датасет с параметрами `VOCAB_SIZE=20'000`, `WIN_SIZE=1000`, `WIN_HOP=100`, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для  всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
        "4. Поменяйте размер словаря tokenaizera (`VOCAB_SIZE`) на `5000`, `10000`, `40000`.  Пересоздайте датасеты, при этом оставьте `WIN_SIZE=1000`, `WIN_HOP=100`.\n",
        "Обучите выбранную нейронку на этих датасетах.  Сделайте выводы об  изменении  точности распознавания авторов текстов. Результаты сведите в таблицу\n",
        "5. Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы  (`WIN_SIZE`, `WIN_HOP`) используя значения (`500`,`50`) и (`2000`,`200`). Пересоздайте датасеты, при этом оставьте `VOCAB_SIZE=20000`. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об  изменении точности распознавания авторов текстов. \n",
        "\n",
        "Результаты всей работы сведите в таблицу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lszru6V_3g3"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4rebeM0PyTH"
      },
      "source": [
        "# Работа с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Функции-утилиты для работы с категориальными данными\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Класс для конструирования последовательной модели нейронной сети\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Основные слои\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "\n",
        "# Токенизатор для преобразование текстов в последовательности\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Рисование схемы модели\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Матрица ошибок классификатора\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Загрузка датасетов из облака google\n",
        "import gdown\n",
        "\n",
        "# Функции операционной системы\n",
        "import os\n",
        "\n",
        "# Работа со временем\n",
        "import time\n",
        "\n",
        "# Регулярные выражения\n",
        "import re\n",
        "\n",
        "# Отрисовка графиков\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Вывод объектов в ячейке colab\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-7of32uP4S-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "35ba297e-fa63-459c-d3d6-99c3af220aa7"
      },
      "source": [
        "# Загрузим датасет из облака\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', None, quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'writers.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsxkrH9rP7MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b52b1ef-0651-4a43-e375-27fc6eae8930"
      },
      "source": [
        "# Распакуем архив в папку writers\n",
        "!unzip -o writers.zip -d writers/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  writers.zip\n",
            "  inflating: writers/(Клиффорд_Саймак) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Клиффорд_Саймак) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(Макс Фрай) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Макс Фрай) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(О. Генри) Обучающая_50 вместе.txt  \n",
            "  inflating: writers/(О. Генри) Тестовая_20 вместе.txt  \n",
            "  inflating: writers/(Рэй Брэдберри) Обучающая_22 вместе.txt  \n",
            "  inflating: writers/(Рэй Брэдберри) Тестовая_8 вместе.txt  \n",
            "  inflating: writers/(Стругацкие) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Стругацкие) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(Булгаков) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Булгаков) Тестовая_2 вместе.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3fICNeqP9li"
      },
      "source": [
        "# Настройка констант для загрузки данных\n",
        "FILE_DIR  = 'writers'                     # Папка с текстовыми файлами\n",
        "SIG_TRAIN = 'обучающая'                   # Признак обучающей выборки в имени файла\n",
        "SIG_TEST  = 'тестовая'                    # Признак тестовой выборки в имени файла"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulfk9v7TQBjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f26d3b-8f2a-487a-b7a4-5d078aca613c"
      },
      "source": [
        "# Подготовим пустые списки\n",
        "\n",
        "CLASS_LIST = []  # Список классов \n",
        "text_train = []  # Список для обучающей выборки\n",
        "text_test = []   # Список для тестовой выборки\n",
        "\n",
        "# Получим списка файлов в папке\n",
        "file_list = os.listdir(FILE_DIR)\n",
        "\n",
        "for file_name in file_list:\n",
        "    # Выделяем имя класса и типа выборки из имени файла\n",
        "    m = re.match('\\((.+)\\) (\\S+)_', file_name)\n",
        "    # Если выделение получилось, то файл обрабатываем\n",
        "    if m:\n",
        "\n",
        "        # Получим имя класса\n",
        "        class_name = m[1]\n",
        "\n",
        "        # Получим имя выборки\n",
        "        subset_name = m[2].lower()\n",
        "\n",
        "        # Проверим тип выборки \n",
        "        is_train = SIG_TRAIN in subset_name\n",
        "        is_test = SIG_TEST in subset_name\n",
        "\n",
        "        # Если тип выборки обучающая либо тестовая - файл обрабатываем\n",
        "        if is_train or is_test:\n",
        "\n",
        "            # Добавляем новый класс, если его еще нет в списке\n",
        "            if class_name not in CLASS_LIST:\n",
        "                print(f'Добавление класса \"{class_name}\"')\n",
        "                CLASS_LIST.append(class_name)\n",
        "\n",
        "                # Инициализируем соответствующих классу строки текста\n",
        "                text_train.append('')\n",
        "                text_test.append('')\n",
        "\n",
        "            # Найдем индекс класса для добавления содержимого файла в выборку\n",
        "            cls = CLASS_LIST.index(class_name)\n",
        "            print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\", {subset_name} выборка.')\n",
        "\n",
        "            # Откроем файл на чтение  \n",
        "            with open(f'{FILE_DIR}/{file_name}', 'r') as f:  \n",
        "\n",
        "                # Загрузим содержимого файла в строку\n",
        "                text = f.read()\n",
        "            # Определим выборку, куда будет добавлено содержимое\n",
        "            subset = text_train if is_train else text_test\n",
        "\n",
        "            # Добавим текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
        "            subset[cls] += ' ' + text.replace('\\n', ' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавление класса \"Клиффорд_Саймак\"\n",
            "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n",
            "Добавление класса \"Макс Фрай\"\n",
            "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
            "Добавление класса \"Стругацкие\"\n",
            "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n",
            "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
            "Добавление класса \"О. Генри\"\n",
            "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
            "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
            "Добавление класса \"Рэй Брэдберри\"\n",
            "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
            "Добавление класса \"Булгаков\"\n",
            "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
            "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
            "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
            "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n",
            "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoBX2ue9zJAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708e5b97-d2d3-4759-8e04-1156b917bc4e"
      },
      "source": [
        "# Определим количество классов\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "print(CLASS_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWh4j3HWzK6y",
        "outputId": "20d7fcd2-b772-44c8-a42e-1b480bad6392"
      },
      "source": [
        "# Выведем прочитанные классы текстов\n",
        "print(CLASS_LIST)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Клиффорд_Саймак', 'Макс Фрай', 'Стругацкие', 'О. Генри', 'Рэй Брэдберри', 'Булгаков']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GayHNBCCzMg-",
        "outputId": "63b2ae6c-ff31-4507-ad2b-4b6a54c18890"
      },
      "source": [
        "# Посчитаем количество текстов в обучающей выборке\n",
        "print(len(text_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MOn2laWQGwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a46893d-8889-4ce5-b4de-e91dd5bbae6f"
      },
      "source": [
        "# Проверим загрузки: выведем начальные отрывки из каждого класса\n",
        "\n",
        "for cls in range(CLASS_COUNT):                   # Запустим цикл по числу классов\n",
        "    print(f'Класс: {CLASS_LIST[cls]}')           # Выведем имя класса\n",
        "    print(f'  train: {text_train[cls][:200]}')   # Выведем фрагмент обучающей выборки\n",
        "    print(f'  test : {text_test[cls][:200]}')    # Выведем фрагмент тестовой выборки\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Класс: Клиффорд_Саймак\n",
            "  train:  ﻿Всё живое...     Когда я выехал из нашего городишка и повернул на шоссе, позади оказался грузовик. Этакая тяжелая громадина с прицепом, и неслась она во весь дух. Шоссе здесь срезает угол городка, и\n",
            "  test :  ﻿Зачарованное паломничество    1  Гоблин со стропил следил за прячущимся монахом, который шпионил за ученым. Гоблин ненавидел монаха и имел для этого все основания. Монах никого не ненавидел и не люб\n",
            "\n",
            "Класс: Макс Фрай\n",
            "  train:  ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежедневно снится какая-то дичь! – сердито сказал я Джуффину. – Сглазили они меня, что ли? А собственно, по\n",
            "  test :  ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, ответ на закономерный вопрос: «Как меня сюда занесло?» – вряд ли принесёт практическую пользу. Зато пои\n",
            "\n",
            "Класс: Стругацкие\n",
            "  train:  Парень из преисподней     1     Ну и деревня! Сроду я таких деревень не видел и не знал даже, что такие деревни бывают. Дома круглые, бурые, без окон, торчат на сваях, как сторожевые вышки, а под ним\n",
            "  test :  ﻿ОТЕЛЬ «У ПОГИБШЕГО АЛЬПИНИСТА»    ГЛАВА 1     Я остановил машину, вылез и снял черные очки. Все было так, как рассказывал Згут. Отель был двухэтажный, желтый с зеленым, над крыльцом красовалась трау\n",
            "\n",
            "Класс: О. Генри\n",
            "  train:  «Лиса-на-рассвете»   Коралио нежился в полуденном зное, как томная красавица в сурово хранимом гареме. Город лежал у самого моря на полоске наносной земли. Он казался брильянтиком, вкрапленным в ярко\n",
            "  test :  ﻿Багдадская птица   Без всякого сомнения, дух и гений калифа Гаруна аль-Рашида осенил маркграфа Августа-Михаила фон Паульсена Квигга.  Ресторан Квигга находится на Четвертой авеню — на улице, которую\n",
            "\n",
            "Класс: Рэй Брэдберри\n",
            "  train:  ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n",
            "  test :  ﻿Марсианские хроники   МОЕЙ ЖЕНЕ МАРГАРЕТ С ИСКРЕННЕЙ ЛЮБОВЬЮ   «Великое дело – способность удивляться, – сказал философ. – Космические полеты снова сделали всех нас детьми».   Январь 1999  Ракетное \n",
            "\n",
            "Класс: Булгаков\n",
            "  train:  ﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил хло-  пьями. Ветер завыл; сделалась метель.  В одно мгновение темное небо смешалось с  снежным мор\n",
            "  test :  ﻿Дон Кихот ДЕЙСТВУЮЩИЕ ЛИЦА Алонсо Кихано, он же Дон Кихот Ламанчский.  Антония – его племянница.  Ключница Дон Кихота.  Санчо Панса – оруженосец Дон Кихота.  Перо Перес – деревенский священник, лице\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2FgTG41QKaT"
      },
      "source": [
        "# Контекстный менеджер для измерения времени операций\n",
        "# Операция обертывается менеджером с помощью оператора with\n",
        "\n",
        "class timex:\n",
        "    def __enter__(self):\n",
        "        # Фиксация времени старта процесса\n",
        "        self.t = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        # Вывод времени работы\n",
        "        print('Время обработки: {:.2f} с'.format(time.time() - self.t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение"
      ],
      "metadata": {
        "id": "kSqt4mshIKzf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP8G65N-_36M"
      },
      "source": [
        "# Токенизация и построение частотного словаря по обучающим текстам\n",
        "def build_vocab(text_list, vocab_size=10000):\n",
        "  with timex():\n",
        "      # Используется встроенный в Keras токенизатор для разбиения текста и построения частотного словаря\n",
        "      tokenizer = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token='неизвестное_слово', char_level=False)\n",
        "\n",
        "      # Использованы параметры:\n",
        "      # num_words   - объем словаря\n",
        "      # filters     - убираемые из текста ненужные символы\n",
        "      # lower       - приведение слов к нижнему регистру\n",
        "      # split       - разделитель слов\n",
        "      # char_level  - указание разделять по словам, а не по единичным символам\n",
        "      # oov_token   - токен для слов, которые не вошли в словарь\n",
        "\n",
        "      # Построение частотного словаря по обучающим текстам\n",
        "      tokenizer.fit_on_texts(text_list)\n",
        "      \n",
        "      # Построение словаря в виде пар слово - индекс\n",
        "      vocab = list(tokenizer.word_index.items())\n",
        "\n",
        "      # \n",
        "      seq = tokenizer.texts_to_sequences(text_list)\n",
        "\n",
        "      print(\"STATISTICS\")\n",
        "        # Вывод нескольких наиболее часто встречающихся слов\n",
        "      print(vocab[:120])\n",
        "      # Размер словаря может быть больше, чем num_words, но при преобразовании в последовательности\n",
        "      # и векторы bag of words будут учтены только первые num_words слов\n",
        "      print(\"Размер словаря\", len(vocab)) \n",
        "      print(\"Фрагмент обучающего текста:\")\n",
        "      print(\"  В виде оригинального текста:              \", text_list[1][:101])\n",
        "      print(\"  Он же в виде последовательности индексов: \", seq[1][:20])\n",
        "\n",
        "  return vocab, seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверка функции build_vocab\n"
      ],
      "metadata": {
        "id": "88VLjSa1bFvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('TRAIN')\n",
        "vocab_train, seq_train = build_vocab(text_train, 20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_V7M779fcQu",
        "outputId": "f361c033-6356-4cdf-ed6f-4cd9f24004bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN\n",
            "STATISTICS\n",
            "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('я', 5), ('что', 6), ('на', 7), ('с', 8), ('он', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('все', 15), ('у', 16), ('по', 17), ('его', 18), ('к', 19), ('так', 20), ('мне', 21), ('из', 22), ('за', 23), ('меня', 24), ('ты', 25), ('же', 26), ('бы', 27), ('сказал', 28), ('вы', 29), ('было', 30), ('от', 31), ('они', 32), ('мы', 33), ('только', 34), ('да', 35), ('еще', 36), ('она', 37), ('о', 38), ('вот', 39), ('когда', 40), ('если', 41), ('уже', 42), ('был', 43), ('нет', 44), ('ни', 45), ('их', 46), ('ну', 47), ('чтобы', 48), ('до', 49), ('для', 50), ('ему', 51), ('ничего', 52), ('может', 53), ('или', 54), ('даже', 55), ('там', 56), ('очень', 57), ('кто', 58), ('ее', 59), ('тут', 60), ('потом', 61), ('просто', 62), ('чем', 63), ('него', 64), ('быть', 65), ('теперь', 66), ('под', 67), ('где', 68), ('нас', 69), ('есть', 70), ('тебя', 71), ('ли', 72), ('время', 73), ('тебе', 74), ('вас', 75), ('со', 76), ('нибудь', 77), ('во', 78), ('раз', 79), ('этот', 80), ('сейчас', 81), ('вам', 82), ('себя', 83), ('здесь', 84), ('себе', 85), ('этого', 86), ('надо', 87), ('уж', 88), ('будет', 89), ('том', 90), ('можно', 91), ('сам', 92), ('нам', 93), ('были', 94), ('была', 95), ('тоже', 96), ('того', 97), ('один', 98), ('без', 99), ('спросил', 100), ('больше', 101), ('них', 102), ('через', 103), ('ведь', 104), ('человек', 105), ('знаю', 106), ('этом', 107), ('конечно', 108), ('какой', 109), ('почему', 110), ('дело', 111), ('пока', 112), ('глаза', 113), ('андрей', 114), ('потому', 115), ('чего', 116), ('им', 117), ('несколько', 118), ('при', 119), ('совершенно', 120)]\n",
            "Размер словаря 133070\n",
            "Фрагмент обучающего текста:\n",
            "  В виде оригинального текста:                ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежеднев\n",
            "  Он же в виде последовательности индексов:  [1502, 1, 8, 282, 236, 11, 24, 9867, 6101, 3, 144, 7809, 1, 21, 3652, 12831, 238, 12, 19819, 1302]\n",
            "Время обработки: 6.53 с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('TEST')\n",
        "vocab_test, seq_test = build_vocab(text_test, 20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvcVaQlVffZW",
        "outputId": "b50f4fc9-2d32-44b1-b7c2-3d643aabef16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST\n",
            "STATISTICS\n",
            "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('на', 5), ('я', 6), ('что', 7), ('он', 8), ('с', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('его', 15), ('у', 16), ('по', 17), ('к', 18), ('из', 19), ('за', 20), ('все', 21), ('вы', 22), ('так', 23), ('же', 24), ('мне', 25), ('меня', 26), ('ты', 27), ('сказал', 28), ('было', 29), ('бы', 30), ('она', 31), ('от', 32), ('они', 33), ('мы', 34), ('только', 35), ('да', 36), ('о', 37), ('вот', 38), ('уже', 39), ('когда', 40), ('нет', 41), ('если', 42), ('был', 43), ('еще', 44), ('чтобы', 45), ('их', 46), ('ни', 47), ('ну', 48), ('до', 49), ('ему', 50), ('тут', 51), ('даже', 52), ('ее', 53), ('там', 54), ('для', 55), ('или', 56), ('под', 57), ('очень', 58), ('него', 59), ('может', 60), ('кто', 61), ('ничего', 62), ('где', 63), ('вас', 64), ('всё', 65), ('потом', 66), ('ли', 67), ('просто', 68), ('чем', 69), ('быть', 70), ('есть', 71), ('теперь', 72), ('вам', 73), ('время', 74), ('вилли', 75), ('раз', 76), ('со', 77), ('себя', 78), ('этого', 79), ('нас', 80), ('во', 81), ('здесь', 82), ('сейчас', 83), ('надо', 84), ('нибудь', 85), ('этот', 86), ('тебя', 87), ('будет', 88), ('этом', 89), ('человек', 90), ('тебе', 91), ('один', 92), ('спросил', 93), ('была', 94), ('можно', 95), ('себе', 96), ('глаза', 97), ('того', 98), ('больше', 99), ('тоже', 100), ('через', 101), ('были', 102), ('почему', 103), ('конечно', 104), ('без', 105), ('пока', 106), ('потому', 107), ('сам', 108), ('них', 109), ('том', 110), ('ведь', 111), ('ним', 112), ('тогда', 113), ('знаю', 114), ('джим', 115), ('какой', 116), ('совершенно', 117), ('при', 118), ('дело', 119), ('ещё', 120)]\n",
            "Размер словаря 82024\n",
            "Фрагмент обучающего текста:\n",
            "  В виде оригинального текста:                ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, отве\n",
            "  Он же в виде последовательности индексов:  [260, 164, 3403, 40, 1, 127, 10699, 5, 6438, 15206, 32, 1348, 5566, 493, 5, 1, 340, 11, 26, 203]\n",
            "Время обработки: 2.10 с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Статистика по текстам"
      ],
      "metadata": {
        "id": "WRWut34ycv9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция вывода статистики по текстам\n",
        "def print_text_stats(title, texts, sequences, class_labels=CLASS_LIST):\n",
        "    # Суммарное количество символов и слов в тексте\n",
        "    chars = 0\n",
        "    words = 0\n",
        "\n",
        "    print(f'Статистика по {title} текстам:')\n",
        "\n",
        "    # Вывод итогов по всем классам данного набора текстов и их последовательностей индексов\n",
        "    for cls in range(len(class_labels)):\n",
        "        print('{:<15} {:9} символов,{:8} слов'.format(class_labels[cls],\n",
        "                                                      len(texts[cls]),\n",
        "                                                      len(sequences[cls])))\n",
        "        chars += len(texts[cls])\n",
        "        words += len(sequences[cls])\n",
        "\n",
        "    print('----')\n",
        "    print('{:<15} {:9} символов,{:8} слов\\n'.format('В сумме', chars, words))\n",
        "\n",
        "# Вывод итогов по текстам\n",
        "print_text_stats('обучающим', text_train, seq_train)\n",
        "print_text_stats('тестовым', text_test, seq_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZaFByGZcjAJ",
        "outputId": "3659551c-dd71-46a8-8ebf-9ad7b66f380d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Статистика по обучающим текстам:\n",
            "Клиффорд_Саймак   1609508 символов,  251502 слов\n",
            "Макс Фрай         3700011 символов,  568533 слов\n",
            "Стругацкие        2042470 символов,  313012 слов\n",
            "О. Генри          1049518 символов,  160607 слов\n",
            "Рэй Брэдберри     1386455 символов,  214454 слов\n",
            "Булгаков          1765649 символов,  261465 слов\n",
            "----\n",
            "В сумме          11553611 символов, 1769573 слов\n",
            "\n",
            "Статистика по тестовым текстам:\n",
            "Клиффорд_Саймак    318812 символов,   50360 слов\n",
            "Макс Фрай         1278192 символов,  196731 слов\n",
            "Стругацкие         704847 символов,  108621 слов\n",
            "О. Генри           349663 символов,   53238 слов\n",
            "Рэй Брэдберри      868674 символов,  132524 слов\n",
            "Булгаков           875043 символов,  132730 слов\n",
            "----\n",
            "В сумме           4395231 символов,  674204 слов\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции формирования выборки\n",
        "\n",
        "sequence – последовательность индексов;  \n",
        "win_size – размер окна;  \n",
        "hop – шаг окна.  "
      ],
      "metadata": {
        "id": "Z4iz75qvsoH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция разбиения последовательности на отрезки скользящим окном\n",
        "# На входе - последовательность индексов, размер окна, шаг окна\n",
        "def split_sequence(sequence, win_size, hop):\n",
        "    # Последовательность разбивается на части до последнего полного окна\n",
        "    return [sequence[i:i + win_size] for i in range(0, len(sequence) - win_size + 1, hop)]\n",
        "\n",
        "\n",
        "# Функция формирования выборок из последовательностей индексов\n",
        "# формирует выборку отрезков и соответствующих им меток классов в виде one hot encoding\n",
        "def vectorize_sequence(seq_list, win_size, hop):\n",
        "    # В списке последовательности следуют в порядке их классов\n",
        "    # Всего последовательностей в списке ровно столько, сколько классов\n",
        "    class_count = len(seq_list)\n",
        "\n",
        "    # Списки для исходных векторов и категориальных меток класса\n",
        "    x, y = [], []\n",
        "\n",
        "    # Для каждого класса:\n",
        "    for cls in range(class_count):\n",
        "        # Разбиение последовательности класса cls на отрезки\n",
        "        vectors = split_sequence(seq_list[cls], win_size, hop)\n",
        "        # Добавление отрезков в выборку\n",
        "        x += vectors\n",
        "        # Для всех отрезков класса cls добавление меток класса в виде OHE\n",
        "        y += [utils.to_categorical(cls, class_count)] * len(vectors)\n",
        "\n",
        "    # Возврат результатов как numpy-массивов\n",
        "    return np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "8cUXVx0EsukB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции для модели (из-зи ограничений ресурсов убираю всё лишнее)\n",
        "\n",
        "Напишите три уже стандартные функции:\n",
        "\n",
        "первая – создание, компиляция, обучение и вывод статистики по модели;\n",
        "вторая – вывод результатов оценки модели;\n",
        "третья – функция, объединяющая первую и вторую."
      ],
      "metadata": {
        "id": "X75jFt7stY86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция компиляции и обучения модели нейронной сети\n",
        "def compile_train_model(model, \n",
        "                        x_train,\n",
        "                        y_train,\n",
        "                        x_val,\n",
        "                        y_val,\n",
        "                        optimizer='adam',\n",
        "                        epochs=50,\n",
        "                        batch_size=128,\n",
        "                        figsize=(20, 5)):\n",
        "\n",
        "    # Компиляция модели\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Вывод сводки\n",
        "    # model.summary()\n",
        "\n",
        "    # Вывод схемы модели\n",
        "    # display(plot_model(model, dpi=60, show_shapes=True))\n",
        "\n",
        "    # Обучение модели с заданными параметрами\n",
        "    history = model.fit(x_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(x_val, y_val))\n",
        "\n",
        "    # Вывод графиков точности и ошибки\n",
        "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "    # fig.suptitle('График процесса обучения модели')\n",
        "    # ax1.plot(history.history['accuracy'], \n",
        "    #            label='Доля верных ответов на обучающем наборе')\n",
        "    # ax1.plot(history.history['val_accuracy'], \n",
        "    #            label='Доля верных ответов на проверочном наборе')\n",
        "    # ax1.xaxis.get_major_locator().set_params(integer=True)\n",
        "    # ax1.set_xlabel('Эпоха обучения')\n",
        "    # ax1.set_ylabel('Доля верных ответов')\n",
        "    # ax1.legend()\n",
        "\n",
        "    # ax2.plot(history.history['loss'], \n",
        "    #            label='Ошибка на обучающем наборе')\n",
        "    # ax2.plot(history.history['val_loss'], \n",
        "    #            label='Ошибка на проверочном наборе')\n",
        "    # ax2.xaxis.get_major_locator().set_params(integer=True)\n",
        "    # ax2.set_xlabel('Эпоха обучения')\n",
        "    # ax2.set_ylabel('Ошибка')\n",
        "    # ax2.legend()\n",
        "    # plt.show()\n",
        "\n",
        "# Функция вывода результатов оценки модели на заданных данных\n",
        "def eval_model(model, x, y_true,\n",
        "               class_labels=[],\n",
        "               cm_round=3,\n",
        "               title='',\n",
        "               figsize=(10, 10)):\n",
        "    # Вычисление предсказания сети\n",
        "    y_pred = model.predict(x)\n",
        "    # Построение матрицы ошибок\n",
        "    cm = confusion_matrix(np.argmax(y_true, axis=1),\n",
        "                          np.argmax(y_pred, axis=1),\n",
        "                          normalize='true')\n",
        "    # Округление значений матрицы ошибок\n",
        "    cm = np.around(cm, cm_round)\n",
        "\n",
        "    # Отрисовка матрицы ошибок\n",
        "    # fig, ax = plt.subplots(figsize=figsize)\n",
        "    # ax.set_title(f'Нейросеть {title}: матрица ошибок нормализованная', fontsize=18)\n",
        "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "    # disp.plot(ax=ax)\n",
        "    # plt.gca().images[-1].colorbar.remove()  # Стирание ненужной цветовой шкалы\n",
        "    # plt.xlabel('Предсказанные классы', fontsize=16)\n",
        "    # plt.ylabel('Верные классы', fontsize=16)\n",
        "    # fig.autofmt_xdate(rotation=45)          # Наклон меток горизонтальной оси при необходимости\n",
        "    # plt.show()    \n",
        "\n",
        "    print('-'*100)\n",
        "    print(f'Нейросеть: {title}')\n",
        "\n",
        "    # Для каждого класса:\n",
        "    for cls in range(len(class_labels)):\n",
        "        # Определяется индекс класса с максимальным значением предсказания (уверенности)\n",
        "        cls_pred = np.argmax(cm[cls])\n",
        "        # Формируется сообщение о верности или неверности предсказания\n",
        "        msg = 'ВЕРНО :-)' if cls_pred == cls else 'НЕВЕРНО :-('\n",
        "        # Выводится текстовая информация о предсказанном классе и значении уверенности\n",
        "        print('Класс: {:<20} {:3.0f}% сеть отнесла к классу {:<20} - {}'.format(class_labels[cls],\n",
        "                                                                               100. * cm[cls, cls_pred],\n",
        "                                                                               class_labels[cls_pred],\n",
        "                                                                               msg))\n",
        "    avg_accuracy = 100. * cm.diagonal().mean()\n",
        "    # Средняя точность распознавания определяется как среднее диагональных элементов матрицы ошибок\n",
        "    print('\\nСредняя точность распознавания: {:3.0f}%'.format(avg_accuracy))\n",
        "    return avg_accuracy\n",
        "\n",
        "\n",
        "# Совместная функция обучения и оценки модели нейронной сети\n",
        "def compile_train_eval_model(model, \n",
        "                             x_train,\n",
        "                             y_train,\n",
        "                             x_test,\n",
        "                             y_test,\n",
        "                             class_labels=CLASS_LIST,\n",
        "                             title='',\n",
        "                             optimizer='adam',\n",
        "                             epochs=50,\n",
        "                             batch_size=128,\n",
        "                             graph_size=(20, 5),\n",
        "                             cm_size=(10, 10)):\n",
        "\n",
        "    # Компиляция и обучение модели на заданных параметрах\n",
        "    # В качестве проверочных используются тестовые данные\n",
        "    compile_train_model(model, \n",
        "                        x_train, y_train,\n",
        "                        x_test, y_test,\n",
        "                        optimizer=optimizer,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        figsize=graph_size)\n",
        "\n",
        "    # Вывод результатов оценки работы модели на тестовых данных\n",
        "    avg_accuracy = eval_model(model, x_test, y_test, \n",
        "               class_labels=class_labels, \n",
        "               title=title,\n",
        "               figsize=cm_size)\n",
        "    \n",
        "    return avg_accuracy"
      ],
      "metadata": {
        "id": "0ZUvoGM2teXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Основной цикл для модели №13: Embedding(50) + BLSTM(8)x2 + GRU(16)x2 + Dense(200)\n",
        "\n",
        "Подготовьте датасет с параметрами VOCAB_SIZE=20'000, WIN_SIZE=1000, WIN_HOP=100, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
        "Поменяйте размер словаря tokenaizera (VOCAB_SIZE) на 5000, 10000, 40000. Пересоздайте датасеты, при этом оставьте WIN_SIZE=1000, WIN_HOP=100. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об изменении точности распознавания авторов текстов. Результаты сведите в таблицу\n",
        "Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы (WIN_SIZE, WIN_HOP) используя значения (500,50) и (2000,200). Пересоздайте датасеты, при этом оставьте VOCAB_SIZE=20000. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об изменении точности распознавания авторов текстов.\n",
        "Результаты всей работы сведите в таблицу."
      ],
      "metadata": {
        "id": "CA9JYNagxqY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns = ['VOCAB_SIZE', 'WIN_SIZE', 'WIN_HOP', 'avg_accuracy'])\n",
        "\n",
        "for VOCAB_SIZE in [5000, 10000, 20000, 40000]:\n",
        "  vocab_train, seq_train, vocab_test, seq_test = None, None, None, None\n",
        "  vocab_train, seq_train = build_vocab(text_train, VOCAB_SIZE)\n",
        "  vocab_test, seq_test = build_vocab(text_test, VOCAB_SIZE)\n",
        "  for WIN_SIZE in [50, 500, 1000]:\n",
        "    for WIN_HOP in [100, 200, 2000]:\n",
        "      print(3*\"\\n\")\n",
        "      print(80*\"=\")\n",
        "      print(f\"VOCAB_SIZE={VOCAB_SIZE}; WIN_SIZE={WIN_SIZE}; WIN_HOP={WIN_HOP}\")\n",
        "\n",
        "      x_train, y_train, x_test, y_test, model_LSTM_6 = None, None, None, None, None\n",
        "      # Формирование обучающей и тестовой выборок\n",
        "      # with timex():\n",
        "      # Формирование обучающей выборки\n",
        "      x_train, y_train = vectorize_sequence(seq_train, WIN_SIZE, WIN_HOP) \n",
        "      # Формирование тестовой выборки\n",
        "      x_test, y_test = vectorize_sequence(seq_test, WIN_SIZE, WIN_HOP)\n",
        "\n",
        "      # Проверка формы сформированных данных\n",
        "      print(x_train.shape, y_train.shape)\n",
        "      print(x_test.shape, y_test.shape)\n",
        "\n",
        "      # Создание модели\n",
        "      model_LSTM_6 = Sequential()\n",
        "      model_LSTM_6.add(Embedding(VOCAB_SIZE, 50, input_length=WIN_SIZE))\n",
        "      model_LSTM_6.add(SpatialDropout1D(0.4))\n",
        "      model_LSTM_6.add(BatchNormalization())\n",
        "      # Два двунаправленных рекуррентных слоя LSTM\n",
        "      # model_LSTM_6.add(Bidirectional(LSTM(8, return_sequences=True)))\n",
        "      # model_LSTM_6.add(Bidirectional(LSTM(8, return_sequences=True)))\n",
        "      # model_LSTM_6.add(Dropout(0.3))\n",
        "      # model_LSTM_6.add(BatchNormalization())\n",
        "      # Два рекуррентных слоя GRU\n",
        "      model_LSTM_6.add(GRU(16, return_sequences=True, reset_after=True))\n",
        "      model_LSTM_6.add(GRU(16, reset_after=True))\n",
        "      model_LSTM_6.add(Dropout(0.3))\n",
        "      model_LSTM_6.add(BatchNormalization())\n",
        "      # Дополнительный полносвязный слой\n",
        "      model_LSTM_6.add(Dense(200, activation='relu'))\n",
        "      model_LSTM_6.add(Dropout(0.3))\n",
        "      model_LSTM_6.add(BatchNormalization())\n",
        "      model_LSTM_6.add(Dense(CLASS_COUNT, activation='softmax'))\n",
        "\n",
        "      avg_accuracy = compile_train_eval_model(model_LSTM_6,\n",
        "                              x_train, y_train,\n",
        "                              x_test, y_test,\n",
        "                              optimizer='rmsprop',\n",
        "                              epochs=50,\n",
        "                              batch_size=512,\n",
        "                              class_labels=CLASS_LIST,\n",
        "                              title='mynet')\n",
        "      print(f\"{VOCAB_SIZE};{WIN_SIZE};{WIN_HOP};{avg_accuracy}\")\n",
        "      df = df.append({'VOCAB_SIZE' : VOCAB_SIZE, 'WIN_SIZE' : WIN_SIZE, 'WIN_HOP' : WIN_HOP, 'avg_accuracy' : avg_accuracy}, ignore_index = True)\n",
        "      df.to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NHpn5PDyR0L",
        "outputId": "bc0930b7-2471-4373-c9fc-40ca89945eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STATISTICS\n",
            "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('я', 5), ('что', 6), ('на', 7), ('с', 8), ('он', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('все', 15), ('у', 16), ('по', 17), ('его', 18), ('к', 19), ('так', 20), ('мне', 21), ('из', 22), ('за', 23), ('меня', 24), ('ты', 25), ('же', 26), ('бы', 27), ('сказал', 28), ('вы', 29), ('было', 30), ('от', 31), ('они', 32), ('мы', 33), ('только', 34), ('да', 35), ('еще', 36), ('она', 37), ('о', 38), ('вот', 39), ('когда', 40), ('если', 41), ('уже', 42), ('был', 43), ('нет', 44), ('ни', 45), ('их', 46), ('ну', 47), ('чтобы', 48), ('до', 49), ('для', 50), ('ему', 51), ('ничего', 52), ('может', 53), ('или', 54), ('даже', 55), ('там', 56), ('очень', 57), ('кто', 58), ('ее', 59), ('тут', 60), ('потом', 61), ('просто', 62), ('чем', 63), ('него', 64), ('быть', 65), ('теперь', 66), ('под', 67), ('где', 68), ('нас', 69), ('есть', 70), ('тебя', 71), ('ли', 72), ('время', 73), ('тебе', 74), ('вас', 75), ('со', 76), ('нибудь', 77), ('во', 78), ('раз', 79), ('этот', 80), ('сейчас', 81), ('вам', 82), ('себя', 83), ('здесь', 84), ('себе', 85), ('этого', 86), ('надо', 87), ('уж', 88), ('будет', 89), ('том', 90), ('можно', 91), ('сам', 92), ('нам', 93), ('были', 94), ('была', 95), ('тоже', 96), ('того', 97), ('один', 98), ('без', 99), ('спросил', 100), ('больше', 101), ('них', 102), ('через', 103), ('ведь', 104), ('человек', 105), ('знаю', 106), ('этом', 107), ('конечно', 108), ('какой', 109), ('почему', 110), ('дело', 111), ('пока', 112), ('глаза', 113), ('андрей', 114), ('потому', 115), ('чего', 116), ('им', 117), ('несколько', 118), ('при', 119), ('совершенно', 120)]\n",
            "Размер словаря 133070\n",
            "Фрагмент обучающего текста:\n",
            "  В виде оригинального текста:                ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежеднев\n",
            "  Он же в виде последовательности индексов:  [1502, 1, 8, 282, 236, 11, 24, 1, 1, 3, 144, 1, 1, 21, 3652, 1, 238, 12, 1, 1302]\n",
            "Время обработки: 5.39 с\n",
            "STATISTICS\n",
            "[('неизвестное_слово', 1), ('и', 2), ('в', 3), ('не', 4), ('на', 5), ('я', 6), ('что', 7), ('он', 8), ('с', 9), ('а', 10), ('как', 11), ('то', 12), ('это', 13), ('но', 14), ('его', 15), ('у', 16), ('по', 17), ('к', 18), ('из', 19), ('за', 20), ('все', 21), ('вы', 22), ('так', 23), ('же', 24), ('мне', 25), ('меня', 26), ('ты', 27), ('сказал', 28), ('было', 29), ('бы', 30), ('она', 31), ('от', 32), ('они', 33), ('мы', 34), ('только', 35), ('да', 36), ('о', 37), ('вот', 38), ('уже', 39), ('когда', 40), ('нет', 41), ('если', 42), ('был', 43), ('еще', 44), ('чтобы', 45), ('их', 46), ('ни', 47), ('ну', 48), ('до', 49), ('ему', 50), ('тут', 51), ('даже', 52), ('ее', 53), ('там', 54), ('для', 55), ('или', 56), ('под', 57), ('очень', 58), ('него', 59), ('может', 60), ('кто', 61), ('ничего', 62), ('где', 63), ('вас', 64), ('всё', 65), ('потом', 66), ('ли', 67), ('просто', 68), ('чем', 69), ('быть', 70), ('есть', 71), ('теперь', 72), ('вам', 73), ('время', 74), ('вилли', 75), ('раз', 76), ('со', 77), ('себя', 78), ('этого', 79), ('нас', 80), ('во', 81), ('здесь', 82), ('сейчас', 83), ('надо', 84), ('нибудь', 85), ('этот', 86), ('тебя', 87), ('будет', 88), ('этом', 89), ('человек', 90), ('тебе', 91), ('один', 92), ('спросил', 93), ('была', 94), ('можно', 95), ('себе', 96), ('глаза', 97), ('того', 98), ('больше', 99), ('тоже', 100), ('через', 101), ('были', 102), ('почему', 103), ('конечно', 104), ('без', 105), ('пока', 106), ('потому', 107), ('сам', 108), ('них', 109), ('том', 110), ('ведь', 111), ('ним', 112), ('тогда', 113), ('знаю', 114), ('джим', 115), ('какой', 116), ('совершенно', 117), ('при', 118), ('дело', 119), ('ещё', 120)]\n",
            "Размер словаря 82024\n",
            "Фрагмент обучающего текста:\n",
            "  В виде оригинального текста:                ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, отве\n",
            "  Он же в виде последовательности индексов:  [260, 164, 3403, 40, 1, 127, 1, 5, 1, 1, 32, 1348, 1, 493, 5, 1, 340, 11, 26, 203]\n",
            "Время обработки: 2.64 с\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=100\n",
            "(17696, 50) (17696, 6)\n",
            "(6741, 50) (6741, 6)\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - 13s 207ms/step - loss: 2.0705 - accuracy: 0.1991 - val_loss: 1.7346 - val_accuracy: 0.2918\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 5s 142ms/step - loss: 1.8777 - accuracy: 0.2642 - val_loss: 1.7326 - val_accuracy: 0.2918\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - 6s 167ms/step - loss: 1.7734 - accuracy: 0.3072 - val_loss: 1.7361 - val_accuracy: 0.2918\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - 6s 159ms/step - loss: 1.6670 - accuracy: 0.3512 - val_loss: 1.7526 - val_accuracy: 0.2918\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - 6s 166ms/step - loss: 1.5370 - accuracy: 0.4003 - val_loss: 1.8034 - val_accuracy: 0.2767\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - 6s 176ms/step - loss: 1.3450 - accuracy: 0.4761 - val_loss: 1.9376 - val_accuracy: 0.1169\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - 5s 144ms/step - loss: 1.2014 - accuracy: 0.5309 - val_loss: 2.0918 - val_accuracy: 0.0878\n",
            "Epoch 8/50\n",
            "35/35 [==============================] - 6s 182ms/step - loss: 1.0889 - accuracy: 0.5782 - val_loss: 2.2424 - val_accuracy: 0.1405\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - 5s 145ms/step - loss: 0.9942 - accuracy: 0.6182 - val_loss: 2.4596 - val_accuracy: 0.1587\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - 6s 183ms/step - loss: 0.9014 - accuracy: 0.6620 - val_loss: 2.4786 - val_accuracy: 0.1108\n",
            "Epoch 11/50\n",
            "35/35 [==============================] - 5s 148ms/step - loss: 0.8228 - accuracy: 0.6935 - val_loss: 2.5449 - val_accuracy: 0.1362\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - 6s 167ms/step - loss: 0.7488 - accuracy: 0.7265 - val_loss: 2.7032 - val_accuracy: 0.1283\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - 6s 159ms/step - loss: 0.6628 - accuracy: 0.7594 - val_loss: 2.8605 - val_accuracy: 0.1497\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - 5s 149ms/step - loss: 0.5950 - accuracy: 0.7892 - val_loss: 3.4738 - val_accuracy: 0.1911\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - 6s 185ms/step - loss: 0.5347 - accuracy: 0.8117 - val_loss: 3.9821 - val_accuracy: 0.2069\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - 5s 151ms/step - loss: 0.4888 - accuracy: 0.8304 - val_loss: 4.0200 - val_accuracy: 0.1921\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - 6s 186ms/step - loss: 0.4430 - accuracy: 0.8463 - val_loss: 4.2196 - val_accuracy: 0.1758\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - 5s 150ms/step - loss: 0.4077 - accuracy: 0.8573 - val_loss: 4.4411 - val_accuracy: 0.1737\n",
            "Epoch 19/50\n",
            "35/35 [==============================] - 7s 187ms/step - loss: 0.3789 - accuracy: 0.8697 - val_loss: 4.8914 - val_accuracy: 0.1850\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - 5s 152ms/step - loss: 0.3480 - accuracy: 0.8805 - val_loss: 5.0890 - val_accuracy: 0.1835\n",
            "Epoch 21/50\n",
            "35/35 [==============================] - 7s 192ms/step - loss: 0.3247 - accuracy: 0.8922 - val_loss: 5.5332 - val_accuracy: 0.1908\n",
            "Epoch 22/50\n",
            "35/35 [==============================] - 5s 152ms/step - loss: 0.2998 - accuracy: 0.8996 - val_loss: 5.4337 - val_accuracy: 0.1844\n",
            "Epoch 23/50\n",
            "35/35 [==============================] - 6s 185ms/step - loss: 0.2806 - accuracy: 0.9068 - val_loss: 5.9882 - val_accuracy: 0.1949\n",
            "Epoch 24/50\n",
            "35/35 [==============================] - 5s 153ms/step - loss: 0.2609 - accuracy: 0.9140 - val_loss: 5.8372 - val_accuracy: 0.1949\n",
            "Epoch 25/50\n",
            "35/35 [==============================] - 6s 178ms/step - loss: 0.2463 - accuracy: 0.9177 - val_loss: 6.1495 - val_accuracy: 0.1988\n",
            "Epoch 26/50\n",
            "35/35 [==============================] - 6s 164ms/step - loss: 0.2295 - accuracy: 0.9228 - val_loss: 6.2330 - val_accuracy: 0.1939\n",
            "Epoch 27/50\n",
            "35/35 [==============================] - 5s 158ms/step - loss: 0.2135 - accuracy: 0.9287 - val_loss: 6.1947 - val_accuracy: 0.1900\n",
            "Epoch 28/50\n",
            "35/35 [==============================] - 6s 184ms/step - loss: 0.1997 - accuracy: 0.9339 - val_loss: 6.3446 - val_accuracy: 0.1850\n",
            "Epoch 29/50\n",
            "35/35 [==============================] - 6s 163ms/step - loss: 0.1920 - accuracy: 0.9361 - val_loss: 6.5349 - val_accuracy: 0.2025\n",
            "Epoch 30/50\n",
            "35/35 [==============================] - 7s 198ms/step - loss: 0.1771 - accuracy: 0.9406 - val_loss: 6.5594 - val_accuracy: 0.1885\n",
            "Epoch 31/50\n",
            "35/35 [==============================] - 6s 163ms/step - loss: 0.1715 - accuracy: 0.9434 - val_loss: 6.5722 - val_accuracy: 0.1875\n",
            "Epoch 32/50\n",
            "35/35 [==============================] - 7s 194ms/step - loss: 0.1625 - accuracy: 0.9463 - val_loss: 6.7330 - val_accuracy: 0.1979\n",
            "Epoch 33/50\n",
            "35/35 [==============================] - 6s 161ms/step - loss: 0.1539 - accuracy: 0.9486 - val_loss: 6.8839 - val_accuracy: 0.1923\n",
            "Epoch 34/50\n",
            "35/35 [==============================] - 7s 191ms/step - loss: 0.1488 - accuracy: 0.9491 - val_loss: 6.9320 - val_accuracy: 0.1891\n",
            "Epoch 35/50\n",
            "35/35 [==============================] - 6s 159ms/step - loss: 0.1410 - accuracy: 0.9524 - val_loss: 7.1794 - val_accuracy: 0.1884\n",
            "Epoch 36/50\n",
            "35/35 [==============================] - 7s 192ms/step - loss: 0.1395 - accuracy: 0.9538 - val_loss: 7.0596 - val_accuracy: 0.2009\n",
            "Epoch 37/50\n",
            "35/35 [==============================] - 6s 166ms/step - loss: 0.1297 - accuracy: 0.9571 - val_loss: 7.1798 - val_accuracy: 0.2000\n",
            "Epoch 38/50\n",
            "35/35 [==============================] - 7s 197ms/step - loss: 0.1221 - accuracy: 0.9602 - val_loss: 7.2535 - val_accuracy: 0.1939\n",
            "Epoch 39/50\n",
            "35/35 [==============================] - 5s 155ms/step - loss: 0.1203 - accuracy: 0.9591 - val_loss: 7.2402 - val_accuracy: 0.1920\n",
            "Epoch 40/50\n",
            "35/35 [==============================] - 7s 193ms/step - loss: 0.1186 - accuracy: 0.9611 - val_loss: 7.4563 - val_accuracy: 0.1917\n",
            "Epoch 41/50\n",
            "35/35 [==============================] - 6s 161ms/step - loss: 0.1120 - accuracy: 0.9637 - val_loss: 7.3527 - val_accuracy: 0.1930\n",
            "Epoch 42/50\n",
            "35/35 [==============================] - 7s 197ms/step - loss: 0.1011 - accuracy: 0.9658 - val_loss: 7.4482 - val_accuracy: 0.1847\n",
            "Epoch 43/50\n",
            "35/35 [==============================] - 6s 162ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 7.5510 - val_accuracy: 0.1896\n",
            "Epoch 44/50\n",
            "35/35 [==============================] - 7s 198ms/step - loss: 0.0980 - accuracy: 0.9678 - val_loss: 7.6042 - val_accuracy: 0.1909\n",
            "Epoch 45/50\n",
            "35/35 [==============================] - 6s 160ms/step - loss: 0.0967 - accuracy: 0.9682 - val_loss: 7.5782 - val_accuracy: 0.1887\n",
            "Epoch 46/50\n",
            "35/35 [==============================] - 7s 199ms/step - loss: 0.0960 - accuracy: 0.9684 - val_loss: 7.7783 - val_accuracy: 0.1905\n",
            "Epoch 47/50\n",
            "35/35 [==============================] - 6s 159ms/step - loss: 0.0886 - accuracy: 0.9710 - val_loss: 7.7734 - val_accuracy: 0.1998\n",
            "Epoch 48/50\n",
            "35/35 [==============================] - 7s 187ms/step - loss: 0.0885 - accuracy: 0.9719 - val_loss: 7.8997 - val_accuracy: 0.2016\n",
            "Epoch 49/50\n",
            "35/35 [==============================] - 6s 162ms/step - loss: 0.0854 - accuracy: 0.9723 - val_loss: 7.8655 - val_accuracy: 0.1888\n",
            "Epoch 50/50\n",
            "35/35 [==============================] - 7s 190ms/step - loss: 0.0796 - accuracy: 0.9736 - val_loss: 7.9069 - val_accuracy: 0.1834\n",
            "211/211 [==============================] - 4s 15ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак       30% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Макс Фрай             28% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Стругацкие            26% сеть отнесла к классу Стругацкие           - ВЕРНО :-)\n",
            "Класс: О. Генри              27% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         28% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Булгаков              28% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  16%\n",
            "5000;50;100;16.333333333333332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=200\n",
            "(8850, 50) (8850, 6)\n",
            "(3372, 50) (3372, 6)\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 9s 222ms/step - loss: 2.1388 - accuracy: 0.1862 - val_loss: 1.7523 - val_accuracy: 0.2918\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 4s 207ms/step - loss: 1.9478 - accuracy: 0.2327 - val_loss: 1.7361 - val_accuracy: 0.2918\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 3s 160ms/step - loss: 1.8688 - accuracy: 0.2610 - val_loss: 1.7336 - val_accuracy: 0.2918\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 1.8163 - accuracy: 0.2895 - val_loss: 1.7370 - val_accuracy: 0.2918\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 1.7435 - accuracy: 0.3193 - val_loss: 1.7419 - val_accuracy: 0.2918\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 4s 230ms/step - loss: 1.6641 - accuracy: 0.3516 - val_loss: 1.7458 - val_accuracy: 0.2918\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 3s 167ms/step - loss: 1.5794 - accuracy: 0.3884 - val_loss: 1.7638 - val_accuracy: 0.2918\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 1.4779 - accuracy: 0.4241 - val_loss: 1.7796 - val_accuracy: 0.2918\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 1.3425 - accuracy: 0.4774 - val_loss: 1.8153 - val_accuracy: 0.1554\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 4s 225ms/step - loss: 1.2408 - accuracy: 0.5168 - val_loss: 1.9704 - val_accuracy: 0.2767\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 1.1559 - accuracy: 0.5533 - val_loss: 1.9243 - val_accuracy: 0.1071\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 1.0689 - accuracy: 0.5905 - val_loss: 1.9839 - val_accuracy: 0.1400\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 1.0208 - accuracy: 0.6101 - val_loss: 2.5355 - val_accuracy: 0.2900\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 4s 224ms/step - loss: 0.9429 - accuracy: 0.6418 - val_loss: 2.1226 - val_accuracy: 0.0872\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 0.8613 - accuracy: 0.6760 - val_loss: 2.2798 - val_accuracy: 0.1729\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 3s 156ms/step - loss: 0.7987 - accuracy: 0.7122 - val_loss: 2.2194 - val_accuracy: 0.1412\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 0.7477 - accuracy: 0.7254 - val_loss: 2.3408 - val_accuracy: 0.1616\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 4s 221ms/step - loss: 0.6889 - accuracy: 0.7492 - val_loss: 2.7665 - val_accuracy: 0.2405\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 3s 154ms/step - loss: 0.6385 - accuracy: 0.7664 - val_loss: 2.5071 - val_accuracy: 0.1453\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 0.5856 - accuracy: 0.7871 - val_loss: 2.5921 - val_accuracy: 0.1560\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 0.5494 - accuracy: 0.8002 - val_loss: 3.4698 - val_accuracy: 0.2524\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 4s 210ms/step - loss: 0.5008 - accuracy: 0.8203 - val_loss: 2.9427 - val_accuracy: 0.1699\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 3s 162ms/step - loss: 0.4713 - accuracy: 0.8330 - val_loss: 3.1596 - val_accuracy: 0.1984\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 3s 155ms/step - loss: 0.4324 - accuracy: 0.8496 - val_loss: 3.6132 - val_accuracy: 0.2112\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 3s 156ms/step - loss: 0.3952 - accuracy: 0.8617 - val_loss: 3.2848 - val_accuracy: 0.1670\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 3s 195ms/step - loss: 0.3682 - accuracy: 0.8747 - val_loss: 3.4941 - val_accuracy: 0.1616\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 3s 178ms/step - loss: 0.3450 - accuracy: 0.8800 - val_loss: 4.2810 - val_accuracy: 0.1859\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 3s 157ms/step - loss: 0.3130 - accuracy: 0.8934 - val_loss: 4.2534 - val_accuracy: 0.1957\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 0.2873 - accuracy: 0.9016 - val_loss: 4.4621 - val_accuracy: 0.1975\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 3s 189ms/step - loss: 0.2720 - accuracy: 0.9066 - val_loss: 4.8746 - val_accuracy: 0.2174\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 0.2505 - accuracy: 0.9156 - val_loss: 4.9601 - val_accuracy: 0.2026\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 3s 152ms/step - loss: 0.2355 - accuracy: 0.9234 - val_loss: 5.1771 - val_accuracy: 0.1877\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 3s 152ms/step - loss: 0.2228 - accuracy: 0.9238 - val_loss: 5.3505 - val_accuracy: 0.1981\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 3s 151ms/step - loss: 0.2083 - accuracy: 0.9307 - val_loss: 5.4099 - val_accuracy: 0.1815\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 4s 212ms/step - loss: 0.1873 - accuracy: 0.9368 - val_loss: 5.5595 - val_accuracy: 0.1865\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.1845 - accuracy: 0.9363 - val_loss: 6.0962 - val_accuracy: 0.2156\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.1832 - accuracy: 0.9380 - val_loss: 6.0077 - val_accuracy: 0.2020\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 3s 158ms/step - loss: 0.1580 - accuracy: 0.9487 - val_loss: 6.0953 - val_accuracy: 0.1753\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 4s 225ms/step - loss: 0.1454 - accuracy: 0.9493 - val_loss: 6.6852 - val_accuracy: 0.2209\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 3s 162ms/step - loss: 0.1574 - accuracy: 0.9431 - val_loss: 6.4392 - val_accuracy: 0.2120\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 3s 156ms/step - loss: 0.1337 - accuracy: 0.9540 - val_loss: 6.8097 - val_accuracy: 0.2073\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 3s 160ms/step - loss: 0.1351 - accuracy: 0.9541 - val_loss: 6.5579 - val_accuracy: 0.2058\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 4s 224ms/step - loss: 0.1247 - accuracy: 0.9579 - val_loss: 6.6919 - val_accuracy: 0.2040\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 3s 157ms/step - loss: 0.1234 - accuracy: 0.9582 - val_loss: 6.7697 - val_accuracy: 0.1865\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 3s 162ms/step - loss: 0.1177 - accuracy: 0.9591 - val_loss: 7.0503 - val_accuracy: 0.2106\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 3s 162ms/step - loss: 0.1098 - accuracy: 0.9614 - val_loss: 7.0445 - val_accuracy: 0.2055\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 4s 226ms/step - loss: 0.1105 - accuracy: 0.9629 - val_loss: 7.2509 - val_accuracy: 0.2082\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 3s 159ms/step - loss: 0.0851 - accuracy: 0.9718 - val_loss: 7.0558 - val_accuracy: 0.1981\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.0928 - accuracy: 0.9686 - val_loss: 7.1911 - val_accuracy: 0.1942\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 3s 161ms/step - loss: 0.0898 - accuracy: 0.9703 - val_loss: 7.2227 - val_accuracy: 0.1862\n",
            "106/106 [==============================] - 2s 12ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак       30% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Макс Фрай             25% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Стругацкие            26% сеть отнесла к классу Стругацкие           - ВЕРНО :-)\n",
            "Класс: О. Генри              27% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         26% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Булгаков              28% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  18%\n",
            "5000;50;200;17.549999999999997\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=50; WIN_HOP=2000\n",
            "(888, 50) (888, 6)\n",
            "(341, 50) (341, 6)\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 6s 1s/step - loss: 2.3436 - accuracy: 0.1993 - val_loss: 1.7796 - val_accuracy: 0.2903\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.1175 - accuracy: 0.2128 - val_loss: 1.7741 - val_accuracy: 0.2903\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 2.0546 - accuracy: 0.2207 - val_loss: 1.7700 - val_accuracy: 0.2903\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 207ms/step - loss: 1.9229 - accuracy: 0.2770 - val_loss: 1.7664 - val_accuracy: 0.2903\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 209ms/step - loss: 1.9191 - accuracy: 0.2827 - val_loss: 1.7643 - val_accuracy: 0.2903\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 198ms/step - loss: 1.8237 - accuracy: 0.3198 - val_loss: 1.7625 - val_accuracy: 0.2903\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 209ms/step - loss: 1.7917 - accuracy: 0.3277 - val_loss: 1.7613 - val_accuracy: 0.2903\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 1.7527 - accuracy: 0.3074 - val_loss: 1.7605 - val_accuracy: 0.2903\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 201ms/step - loss: 1.7552 - accuracy: 0.3311 - val_loss: 1.7594 - val_accuracy: 0.2903\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 1.6456 - accuracy: 0.3761 - val_loss: 1.7587 - val_accuracy: 0.2903\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 1.6508 - accuracy: 0.3795 - val_loss: 1.7584 - val_accuracy: 0.2903\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 289ms/step - loss: 1.5535 - accuracy: 0.4020 - val_loss: 1.7575 - val_accuracy: 0.2903\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 281ms/step - loss: 1.5306 - accuracy: 0.4099 - val_loss: 1.7578 - val_accuracy: 0.2903\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.4753 - accuracy: 0.4245 - val_loss: 1.7587 - val_accuracy: 0.2903\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 1.4276 - accuracy: 0.4617 - val_loss: 1.7603 - val_accuracy: 0.2903\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 299ms/step - loss: 1.3696 - accuracy: 0.4842 - val_loss: 1.7615 - val_accuracy: 0.2903\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 1.3519 - accuracy: 0.4876 - val_loss: 1.7631 - val_accuracy: 0.2903\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 204ms/step - loss: 1.3029 - accuracy: 0.5079 - val_loss: 1.7661 - val_accuracy: 0.2903\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 1.2789 - accuracy: 0.4932 - val_loss: 1.7698 - val_accuracy: 0.2903\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 207ms/step - loss: 1.1848 - accuracy: 0.5473 - val_loss: 1.7715 - val_accuracy: 0.2903\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.1857 - accuracy: 0.5507 - val_loss: 1.7729 - val_accuracy: 0.2903\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 213ms/step - loss: 1.1354 - accuracy: 0.5642 - val_loss: 1.7750 - val_accuracy: 0.2903\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 1.0720 - accuracy: 0.5946 - val_loss: 1.7788 - val_accuracy: 0.2903\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 1.0081 - accuracy: 0.6216 - val_loss: 1.7831 - val_accuracy: 0.2903\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.9750 - accuracy: 0.6374 - val_loss: 1.7812 - val_accuracy: 0.2903\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.9266 - accuracy: 0.6577 - val_loss: 1.7837 - val_accuracy: 0.2903\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.8993 - accuracy: 0.6577 - val_loss: 1.7889 - val_accuracy: 0.2903\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 208ms/step - loss: 0.8646 - accuracy: 0.6903 - val_loss: 1.7919 - val_accuracy: 0.2903\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 167ms/step - loss: 0.8070 - accuracy: 0.6959 - val_loss: 1.7951 - val_accuracy: 0.2903\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.7837 - accuracy: 0.7095 - val_loss: 1.7967 - val_accuracy: 0.2903\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 0.7103 - accuracy: 0.7365 - val_loss: 1.7981 - val_accuracy: 0.2903\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.7079 - accuracy: 0.7331 - val_loss: 1.7988 - val_accuracy: 0.2903\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 0.6577 - accuracy: 0.7624 - val_loss: 1.8027 - val_accuracy: 0.2903\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 204ms/step - loss: 0.6490 - accuracy: 0.7736 - val_loss: 1.8045 - val_accuracy: 0.2903\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.5972 - accuracy: 0.7635 - val_loss: 1.8116 - val_accuracy: 0.2903\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 199ms/step - loss: 0.5788 - accuracy: 0.7860 - val_loss: 1.8164 - val_accuracy: 0.2903\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 204ms/step - loss: 0.5431 - accuracy: 0.8097 - val_loss: 1.8178 - val_accuracy: 0.2903\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 0.5176 - accuracy: 0.8187 - val_loss: 1.8249 - val_accuracy: 0.2903\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.4757 - accuracy: 0.8367 - val_loss: 1.8247 - val_accuracy: 0.2903\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 0.4756 - accuracy: 0.8311 - val_loss: 1.8284 - val_accuracy: 0.2903\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 176ms/step - loss: 0.4380 - accuracy: 0.8547 - val_loss: 1.8345 - val_accuracy: 0.2903\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 0.4181 - accuracy: 0.8559 - val_loss: 1.8381 - val_accuracy: 0.2903\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 0.3847 - accuracy: 0.8649 - val_loss: 1.8442 - val_accuracy: 0.2903\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 0.4033 - accuracy: 0.8637 - val_loss: 1.8500 - val_accuracy: 0.2845\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 0.3384 - accuracy: 0.8896 - val_loss: 1.8536 - val_accuracy: 0.2903\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.2975 - accuracy: 0.9054 - val_loss: 1.8543 - val_accuracy: 0.2874\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 1s 294ms/step - loss: 0.2870 - accuracy: 0.9054 - val_loss: 1.8604 - val_accuracy: 0.2903\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.3128 - accuracy: 0.8818 - val_loss: 1.8625 - val_accuracy: 0.2903\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.2825 - accuracy: 0.9099 - val_loss: 1.8675 - val_accuracy: 0.2903\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 1s 285ms/step - loss: 0.2889 - accuracy: 0.8998 - val_loss: 1.8731 - val_accuracy: 0.2874\n",
            "11/11 [==============================] - 1s 11ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак      100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Макс Фрай             99% сеть отнесла к классу Макс Фрай            - ВЕРНО :-)\n",
            "Класс: Стругацкие           100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: О. Генри             100% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         96% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "Класс: Булгаков              98% сеть отнесла к классу Макс Фрай            - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  16%\n",
            "5000;50;2000;16.5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=500; WIN_HOP=100\n",
            "(17670, 500) (17670, 6)\n",
            "(6716, 500) (6716, 6)\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - 70s 2s/step - loss: 2.0377 - accuracy: 0.2134 - val_loss: 1.7413 - val_accuracy: 0.2923\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 60s 2s/step - loss: 1.8593 - accuracy: 0.2683 - val_loss: 1.7402 - val_accuracy: 0.2923\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 1.7329 - accuracy: 0.3243 - val_loss: 1.7428 - val_accuracy: 0.2923\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - 57s 2s/step - loss: 1.5997 - accuracy: 0.3829 - val_loss: 1.7636 - val_accuracy: 0.2466\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 1.3858 - accuracy: 0.4626 - val_loss: 1.9736 - val_accuracy: 0.1611\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - 62s 2s/step - loss: 1.1745 - accuracy: 0.5358 - val_loss: 2.0757 - val_accuracy: 0.1611\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - 57s 2s/step - loss: 1.0526 - accuracy: 0.5860 - val_loss: 3.2027 - val_accuracy: 0.2856\n",
            "Epoch 8/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.9158 - accuracy: 0.6439 - val_loss: 3.9847 - val_accuracy: 0.2920\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - 57s 2s/step - loss: 0.7758 - accuracy: 0.6977 - val_loss: 2.9776 - val_accuracy: 0.1300\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.6884 - accuracy: 0.7308 - val_loss: 3.3048 - val_accuracy: 0.1415\n",
            "Epoch 11/50\n",
            "35/35 [==============================] - 62s 2s/step - loss: 0.5701 - accuracy: 0.7798 - val_loss: 5.2927 - val_accuracy: 0.2594\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.4979 - accuracy: 0.8099 - val_loss: 4.4968 - val_accuracy: 0.1219\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - 57s 2s/step - loss: 0.4286 - accuracy: 0.8364 - val_loss: 4.6545 - val_accuracy: 0.1379\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.3501 - accuracy: 0.8688 - val_loss: 5.0508 - val_accuracy: 0.1353\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.2991 - accuracy: 0.8916 - val_loss: 5.3236 - val_accuracy: 0.1420\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.2343 - accuracy: 0.9170 - val_loss: 6.8059 - val_accuracy: 0.1404\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.2059 - accuracy: 0.9266 - val_loss: 8.5970 - val_accuracy: 0.2134\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.1854 - accuracy: 0.9383 - val_loss: 7.3304 - val_accuracy: 0.1485\n",
            "Epoch 19/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.1529 - accuracy: 0.9471 - val_loss: 7.3812 - val_accuracy: 0.1403\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.1198 - accuracy: 0.9612 - val_loss: 7.6969 - val_accuracy: 0.1440\n",
            "Epoch 21/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.1123 - accuracy: 0.9635 - val_loss: 7.6468 - val_accuracy: 0.1407\n",
            "Epoch 22/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.0866 - accuracy: 0.9728 - val_loss: 7.9308 - val_accuracy: 0.1468\n",
            "Epoch 23/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.0775 - accuracy: 0.9763 - val_loss: 7.5336 - val_accuracy: 0.1434\n",
            "Epoch 24/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 8.0251 - val_accuracy: 0.1394\n",
            "Epoch 25/50\n",
            "35/35 [==============================] - 60s 2s/step - loss: 0.0535 - accuracy: 0.9841 - val_loss: 8.4199 - val_accuracy: 0.1486\n",
            "Epoch 26/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0497 - accuracy: 0.9847 - val_loss: 8.2731 - val_accuracy: 0.1479\n",
            "Epoch 27/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 8.3000 - val_accuracy: 0.1467\n",
            "Epoch 28/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 8.4864 - val_accuracy: 0.1423\n",
            "Epoch 29/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 8.6416 - val_accuracy: 0.1456\n",
            "Epoch 30/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 8.7886 - val_accuracy: 0.1446\n",
            "Epoch 31/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 9.0358 - val_accuracy: 0.1404\n",
            "Epoch 32/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 10.8100 - val_accuracy: 0.1812\n",
            "Epoch 33/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 9.2872 - val_accuracy: 0.1492\n",
            "Epoch 34/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 9.6841 - val_accuracy: 0.1443\n",
            "Epoch 35/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 9.7814 - val_accuracy: 0.1432\n",
            "Epoch 36/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 9.6757 - val_accuracy: 0.1498\n",
            "Epoch 37/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 9.6407 - val_accuracy: 0.1490\n",
            "Epoch 38/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 9.9326 - val_accuracy: 0.1429\n",
            "Epoch 39/50\n",
            "35/35 [==============================] - 58s 2s/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 9.8327 - val_accuracy: 0.1477\n",
            "Epoch 40/50\n",
            "35/35 [==============================] - 64s 2s/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 9.9274 - val_accuracy: 0.1397\n",
            "Epoch 41/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 10.0404 - val_accuracy: 0.1479\n",
            "Epoch 42/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 10.7752 - val_accuracy: 0.1532\n",
            "Epoch 43/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 9.9461 - val_accuracy: 0.1449\n",
            "Epoch 44/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 10.6810 - val_accuracy: 0.1531\n",
            "Epoch 45/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 10.2808 - val_accuracy: 0.1467\n",
            "Epoch 46/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 10.3922 - val_accuracy: 0.1483\n",
            "Epoch 47/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 9.9864 - val_accuracy: 0.1489\n",
            "Epoch 48/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 10.6908 - val_accuracy: 0.1513\n",
            "Epoch 49/50\n",
            "35/35 [==============================] - 63s 2s/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 10.8190 - val_accuracy: 0.1495\n",
            "Epoch 50/50\n",
            "35/35 [==============================] - 59s 2s/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 10.4932 - val_accuracy: 0.1476\n",
            "210/210 [==============================] - 19s 87ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак       31% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Макс Фрай             37% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Стругацкие            36% сеть отнесла к классу Стругацкие           - ВЕРНО :-)\n",
            "Класс: О. Генри              39% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         27% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Булгаков              27% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  17%\n",
            "5000;500;100;16.633333333333333\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=500; WIN_HOP=200\n",
            "(8836, 500) (8836, 6)\n",
            "(3360, 500) (3360, 6)\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 37s 2s/step - loss: 2.1427 - accuracy: 0.1949 - val_loss: 1.7499 - val_accuracy: 0.2923\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 30s 2s/step - loss: 1.9670 - accuracy: 0.2347 - val_loss: 1.7374 - val_accuracy: 0.2923\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 1.8882 - accuracy: 0.2581 - val_loss: 1.7339 - val_accuracy: 0.2923\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 32s 2s/step - loss: 1.8287 - accuracy: 0.2867 - val_loss: 1.7347 - val_accuracy: 0.2923\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 30s 2s/step - loss: 1.7674 - accuracy: 0.3141 - val_loss: 1.7363 - val_accuracy: 0.2923\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 31s 2s/step - loss: 1.7021 - accuracy: 0.3408 - val_loss: 1.7427 - val_accuracy: 0.2923\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 1.6115 - accuracy: 0.3785 - val_loss: 1.7518 - val_accuracy: 0.2923\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 1.5261 - accuracy: 0.4072 - val_loss: 1.7674 - val_accuracy: 0.2923\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 1.4352 - accuracy: 0.4425 - val_loss: 1.7894 - val_accuracy: 0.2908\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 1.3112 - accuracy: 0.4851 - val_loss: 1.8117 - val_accuracy: 0.1598\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 1.1815 - accuracy: 0.5437 - val_loss: 1.8879 - val_accuracy: 0.1571\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 1.0915 - accuracy: 0.5705 - val_loss: 2.0425 - val_accuracy: 0.1006\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 1.0104 - accuracy: 0.5996 - val_loss: 5.3342 - val_accuracy: 0.2923\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.9475 - accuracy: 0.6346 - val_loss: 2.1276 - val_accuracy: 0.1628\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.8850 - accuracy: 0.6605 - val_loss: 2.5485 - val_accuracy: 0.1134\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.8270 - accuracy: 0.6862 - val_loss: 2.4786 - val_accuracy: 0.1068\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.7719 - accuracy: 0.7095 - val_loss: 2.4543 - val_accuracy: 0.1604\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.7309 - accuracy: 0.7244 - val_loss: 2.6834 - val_accuracy: 0.1262\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.6677 - accuracy: 0.7517 - val_loss: 3.1230 - val_accuracy: 0.1524\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.6264 - accuracy: 0.7704 - val_loss: 2.8334 - val_accuracy: 0.1497\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.5575 - accuracy: 0.7962 - val_loss: 3.0650 - val_accuracy: 0.1429\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.5384 - accuracy: 0.8031 - val_loss: 3.0721 - val_accuracy: 0.1402\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.4890 - accuracy: 0.8173 - val_loss: 5.1557 - val_accuracy: 0.2414\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.4779 - accuracy: 0.8267 - val_loss: 4.8440 - val_accuracy: 0.2259\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.4216 - accuracy: 0.8490 - val_loss: 3.6993 - val_accuracy: 0.1530\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 32s 2s/step - loss: 0.3856 - accuracy: 0.8637 - val_loss: 4.0201 - val_accuracy: 0.1485\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.3483 - accuracy: 0.8774 - val_loss: 8.2594 - val_accuracy: 0.2857\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.3175 - accuracy: 0.8903 - val_loss: 4.9773 - val_accuracy: 0.1824\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 32s 2s/step - loss: 0.3199 - accuracy: 0.8923 - val_loss: 7.3568 - val_accuracy: 0.2595\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.2509 - accuracy: 0.9143 - val_loss: 6.5667 - val_accuracy: 0.2277\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.2156 - accuracy: 0.9251 - val_loss: 8.9277 - val_accuracy: 0.2842\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.2222 - accuracy: 0.9264 - val_loss: 7.8984 - val_accuracy: 0.2491\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.1979 - accuracy: 0.9353 - val_loss: 6.2705 - val_accuracy: 0.1854\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.1709 - accuracy: 0.9393 - val_loss: 6.6157 - val_accuracy: 0.1997\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.1732 - accuracy: 0.9425 - val_loss: 5.8406 - val_accuracy: 0.1574\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.1565 - accuracy: 0.9504 - val_loss: 5.9206 - val_accuracy: 0.1518\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.1174 - accuracy: 0.9610 - val_loss: 7.5742 - val_accuracy: 0.2131\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.1369 - accuracy: 0.9554 - val_loss: 6.2795 - val_accuracy: 0.1646\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.1052 - accuracy: 0.9677 - val_loss: 6.6879 - val_accuracy: 0.1554\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0973 - accuracy: 0.9653 - val_loss: 6.7027 - val_accuracy: 0.1655\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 32s 2s/step - loss: 0.0895 - accuracy: 0.9731 - val_loss: 7.9117 - val_accuracy: 0.1827\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0809 - accuracy: 0.9734 - val_loss: 6.9230 - val_accuracy: 0.1494\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0931 - accuracy: 0.9715 - val_loss: 6.9041 - val_accuracy: 0.1506\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 7.2943 - val_accuracy: 0.1554\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0712 - accuracy: 0.9785 - val_loss: 7.2216 - val_accuracy: 0.1679\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 35s 2s/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 7.5249 - val_accuracy: 0.1688\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 8.0713 - val_accuracy: 0.1598\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 7.9318 - val_accuracy: 0.1685\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 34s 2s/step - loss: 0.0495 - accuracy: 0.9849 - val_loss: 7.8898 - val_accuracy: 0.1574\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 33s 2s/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 7.8503 - val_accuracy: 0.1598\n",
            "105/105 [==============================] - 11s 96ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак       39% сеть отнесла к классу Клиффорд_Саймак      - ВЕРНО :-)\n",
            "Класс: Макс Фрай             38% сеть отнесла к классу Клиффорд_Саймак      - НЕВЕРНО :-(\n",
            "Класс: Стругацкие            41% сеть отнесла к классу Клиффорд_Саймак      - НЕВЕРНО :-(\n",
            "Класс: О. Генри              40% сеть отнесла к классу Клиффорд_Саймак      - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         38% сеть отнесла к классу Клиффорд_Саймак      - НЕВЕРНО :-(\n",
            "Класс: Булгаков              37% сеть отнесла к классу Клиффорд_Саймак      - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  17%\n",
            "5000;500;200;16.833333333333332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=500; WIN_HOP=2000\n",
            "(887, 500) (887, 6)\n",
            "(340, 500) (340, 6)\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 10s 3s/step - loss: 2.4661 - accuracy: 0.1883 - val_loss: 1.7809 - val_accuracy: 0.2912\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 2.1649 - accuracy: 0.2277 - val_loss: 1.7742 - val_accuracy: 0.2912\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 2.0629 - accuracy: 0.2198 - val_loss: 1.7693 - val_accuracy: 0.2912\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 2.0250 - accuracy: 0.2401 - val_loss: 1.7654 - val_accuracy: 0.2912\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.9270 - accuracy: 0.2390 - val_loss: 1.7622 - val_accuracy: 0.2912\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.8736 - accuracy: 0.2864 - val_loss: 1.7593 - val_accuracy: 0.2912\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.7999 - accuracy: 0.3179 - val_loss: 1.7573 - val_accuracy: 0.2912\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 1.7575 - accuracy: 0.3236 - val_loss: 1.7562 - val_accuracy: 0.2912\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.7411 - accuracy: 0.3224 - val_loss: 1.7556 - val_accuracy: 0.2912\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.7521 - accuracy: 0.3382 - val_loss: 1.7556 - val_accuracy: 0.2912\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.6933 - accuracy: 0.3653 - val_loss: 1.7540 - val_accuracy: 0.2912\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 4s 1s/step - loss: 1.6231 - accuracy: 0.3754 - val_loss: 1.7530 - val_accuracy: 0.2912\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.5802 - accuracy: 0.3935 - val_loss: 1.7532 - val_accuracy: 0.2912\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.5281 - accuracy: 0.4318 - val_loss: 1.7544 - val_accuracy: 0.2912\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.4677 - accuracy: 0.4431 - val_loss: 1.7548 - val_accuracy: 0.2912\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.4570 - accuracy: 0.4543 - val_loss: 1.7561 - val_accuracy: 0.2912\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.4160 - accuracy: 0.4532 - val_loss: 1.7574 - val_accuracy: 0.2912\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.3414 - accuracy: 0.4938 - val_loss: 1.7584 - val_accuracy: 0.2912\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 1.3569 - accuracy: 0.4904 - val_loss: 1.7601 - val_accuracy: 0.2912\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.3128 - accuracy: 0.4961 - val_loss: 1.7631 - val_accuracy: 0.2912\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.2022 - accuracy: 0.5389 - val_loss: 1.7659 - val_accuracy: 0.2912\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.2202 - accuracy: 0.5366 - val_loss: 1.7665 - val_accuracy: 0.2912\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 1.1205 - accuracy: 0.5772 - val_loss: 1.7695 - val_accuracy: 0.2912\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.0735 - accuracy: 0.6009 - val_loss: 1.7721 - val_accuracy: 0.2912\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.0858 - accuracy: 0.5998 - val_loss: 1.7747 - val_accuracy: 0.2853\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.0148 - accuracy: 0.6065 - val_loss: 1.7787 - val_accuracy: 0.2588\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.9746 - accuracy: 0.6144 - val_loss: 1.7834 - val_accuracy: 0.1824\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.9562 - accuracy: 0.6359 - val_loss: 1.7864 - val_accuracy: 0.1647\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.9414 - accuracy: 0.6528 - val_loss: 1.7898 - val_accuracy: 0.1618\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.9455 - accuracy: 0.6550 - val_loss: 1.7926 - val_accuracy: 0.1647\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.8970 - accuracy: 0.6561 - val_loss: 1.7964 - val_accuracy: 0.1676\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.8282 - accuracy: 0.6945 - val_loss: 1.7994 - val_accuracy: 0.1618\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7894 - accuracy: 0.7024 - val_loss: 1.8049 - val_accuracy: 0.1647\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.7599 - accuracy: 0.7159 - val_loss: 1.8086 - val_accuracy: 0.1618\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.7168 - accuracy: 0.7351 - val_loss: 1.8158 - val_accuracy: 0.1618\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.7338 - accuracy: 0.7294 - val_loss: 1.8191 - val_accuracy: 0.1618\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6532 - accuracy: 0.7576 - val_loss: 1.8252 - val_accuracy: 0.1618\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.6214 - accuracy: 0.7790 - val_loss: 1.8294 - val_accuracy: 0.1618\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.6327 - accuracy: 0.7632 - val_loss: 1.8276 - val_accuracy: 0.1618\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5495 - accuracy: 0.8038 - val_loss: 1.8343 - val_accuracy: 0.1618\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.5685 - accuracy: 0.8061 - val_loss: 1.8420 - val_accuracy: 0.1618\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 4s 2s/step - loss: 0.5588 - accuracy: 0.8072 - val_loss: 1.8440 - val_accuracy: 0.1618\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4769 - accuracy: 0.8309 - val_loss: 1.8480 - val_accuracy: 0.1618\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4793 - accuracy: 0.8320 - val_loss: 1.8537 - val_accuracy: 0.1618\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4467 - accuracy: 0.8467 - val_loss: 1.8645 - val_accuracy: 0.1618\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.4362 - accuracy: 0.8444 - val_loss: 1.8724 - val_accuracy: 0.1618\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.4164 - accuracy: 0.8444 - val_loss: 1.8839 - val_accuracy: 0.1618\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3873 - accuracy: 0.8625 - val_loss: 1.8924 - val_accuracy: 0.1618\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 3s 2s/step - loss: 0.3595 - accuracy: 0.8749 - val_loss: 1.8943 - val_accuracy: 0.1618\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3576 - accuracy: 0.8861 - val_loss: 1.8994 - val_accuracy: 0.1618\n",
            "11/11 [==============================] - 2s 87ms/step\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Нейросеть: mynet\n",
            "Класс: Клиффорд_Саймак      100% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Макс Фрай            100% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Стругацкие           100% сеть отнесла к классу Стругацкие           - ВЕРНО :-)\n",
            "Класс: О. Генри              96% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Рэй Брэдберри         98% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "Класс: Булгаков             100% сеть отнесла к классу Стругацкие           - НЕВЕРНО :-(\n",
            "\n",
            "Средняя точность распознавания:  17%\n",
            "5000;500;2000;16.666666666666664\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "VOCAB_SIZE=5000; WIN_SIZE=1000; WIN_HOP=100\n",
            "(17640, 1000) (17640, 6)\n",
            "(6686, 1000) (6686, 6)\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Результирующая таблица"
      ],
      "metadata": {
        "id": "nZZR6nlXKqqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "lPD2TlJzKvFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}